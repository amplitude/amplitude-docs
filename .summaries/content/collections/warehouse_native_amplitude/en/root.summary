Warehouse-native Amplitude (WNA) is a data analytics platform that enables organizations to perform custom analytics directly on their Snowflake data warehouse without requiring data ingestion into Amplitude's systems. This approach allows companies to maintain data sovereignty while leveraging Amplitude's analytics capabilities on their existing warehouse infrastructure.

## Product Architecture and Feature Relationships

WNA operates through a direct, read-only connection to Snowflake data warehouses, establishing one connection per Amplitude project. The platform supports multiple data modeling approaches through three primary interfaces:

**Manual Data Model Creation**: Users can build individual warehouse-native data models through Amplitude's interface using either Table Selection or SQL Query options. This supports various data types including events (fact tables), user properties, group properties, and event properties, each requiring specific mandatory fields like unique IDs and timestamps.

**Bulk Model Management**: A YAML-based configuration system enables batch creation and updating of multiple data models simultaneously. This approach uses DataModel objects with tableConfig or sqlConfig specifications, supporting the same data types as manual creation but with enhanced efficiency for large-scale deployments.

**DBT Integration**: The platform integrates with DBT (Data Build Tool) workflows through manifest file annotations using `amplitude_meta` metadata configuration. This enables data teams to manage Amplitude models within their existing DBT infrastructure, supporting all six core data model types through special column mappings.

## Key Nomenclature and Definitions

**Data Model Types**: WNA supports six distinct model types:
- EVENT: Fact table events with event_time, unique_id, and event_type fields
- EVENT_PROPERTIES: Additional attributes associated with events
- CURRENT_USER_PROPERTIES and HISTORICAL_USER_PROPERTIES: User attribute data in current state or time-series format
- CURRENT_GROUP_PROPERTIES and HISTORICAL_GROUP_PROPERTIES: Group-level attributes in current state or time-series format

**Schema Patterns**: The platform supports both star schema (centralized fact table with dimension tables) and snowflake schema (normalized dimension tables) approaches, with specific optimization recommendations for each.

**Clustering and Partitioning**: Performance optimization through clustering keys (including LINEAR() function for event time), composite clustering keys for high cardinality columns, and table partitioning strategies for efficient query execution.

**Identity Spaces**: User identification frameworks that map different user identifiers across the data model, supporting MTU (Monthly Tracked Users) counting and user journey analysis.

## Product Ecosystem Integration

WNA integrates into the broader Amplitude ecosystem while maintaining data warehouse independence. The platform generates and executes queries directly against Snowflake, requiring service account setup with read-only credentials and clustering key optimization for performance.

The system supports standard Amplitude analytics features with specific limitations:
- Formula constraints affecting HIST, PERCENTILE, ROLLWINBEFORE, CUMSUM, ACTIVE, and ARPAU functions
- Event segmentation, funnel analysis, retention analysis, cohort segmentation, and journey analysis restrictions
- Single connection limitation per project

## Technical Implementation

**API and Configuration**: The bulk management system uses YAML configuration files with apiVersion, metadata, and spec sections. DBT integration leverages manifest file parsing with amplitude_meta annotations for model configuration.

**Data Modeling Approaches**: Two primary patterns are supported:
- One event per table: Dedicated tables for each event type
- Multiple events per table: Single table containing multiple event types with event_type differentiation

**Required Fields Configuration**: All models require specific field mappings including eventTime (TIMESTAMP_NTZ format), userId, groupId, eventId, and for historical models, startTime and endTime fields. Event properties require eventJoinField configuration for proper relationship mapping.

**Performance Optimization**: The platform emphasizes clustering key selection, particularly using LINEAR() functions for time-based clustering, composite keys for high cardinality scenarios, and appropriate schema design patterns to optimize analytical workload performance while maintaining data storage efficiency.