# Warehouse-native Amplitude (WNA)

## Product Overview

Warehouse-native Amplitude (WNA) is an analytics solution that allows users to perform custom analyses directly on data stored in their Snowflake data warehouse without requiring data ingestion into Amplitude's systems. This approach provides faster access to time-sensitive datasets while leveraging Amplitude's analytical capabilities. WNA establishes a read-only connection to the customer's Snowflake instance, enabling analysis of warehouse data through Amplitude's interface.

### Key Features
- Direct connection to Snowflake data warehouse
- Custom data modeling capabilities
- Support for various data types (events, user properties, group properties)
- Multiple modeling approaches (one event per table or many events in a single table)
- Bulk model management through YAML configuration
- DBT integration for streamlined data modeling
- Performance optimization through clustering keys and partitioning

### Primary Use Cases
- Analyzing time-sensitive data without data transfer delays
- Leveraging existing data warehouse investments
- Creating custom analytics models on warehouse data
- Maintaining data governance within existing warehouse infrastructure

## Product Relationships and Features

### Data Model Components
1. **Event Data**: Core behavioral data representing user actions
2. **User Properties**: Attributes describing users
3. **Group Properties**: Attributes describing organizational groups
4. **Fact Tables**: Primary tables containing event data
5. **Dimension Tables**: Supporting tables with descriptive attributes

### Modeling Approaches
1. **Table Selection**: Direct mapping to existing Snowflake tables
2. **SQL Query**: Custom SQL queries to transform and prepare data
3. **Star Schema**: Fact table connected directly to dimension tables
4. **Snowflake Schema**: Fact table connected to normalized dimension tables

### Integration Methods
1. **Direct Snowflake Connection**: Read-only credentials for secure access
2. **YAML Configuration**: Bulk model management through configuration files
3. **DBT Integration**: Leveraging DBT manifest files with Amplitude-specific annotations

## Key Nomenclature and Definitions

### Data Model Types
- **EVENT**: Represents user actions or behaviors
- **EVENT_PROPERTIES**: Additional attributes describing events
- **CURRENT_USER_PROPERTIES**: Latest state of user attributes
- **HISTORICAL_USER_PROPERTIES**: Time-series record of user attribute changes
- **CURRENT_GROUP_PROPERTIES**: Latest state of group attributes
- **HISTORICAL_GROUP_PROPERTIES**: Time-series record of group attribute changes

### Technical Concepts
- **Clustering Keys**: Columns used to physically organize data for query optimization
- **Composite Clustering Keys**: Multiple columns used together for clustering
- **LINEAR() Function**: Snowflake function used with clustering keys
- **Identity Spaces**: Namespaces for user identification across data sources
- **Partitioning**: Division of data into segments for improved query performance
- **Cardinality**: Measure of uniqueness in a data column

### Configuration Elements
- **TableConfig**: Configuration for direct table mapping
- **SQLConfig**: Configuration for SQL-based model creation
- **FieldMapping**: Mapping between source and destination fields
- **RequiredFields**: Mandatory fields for specific model types
- **amplitude_meta**: DBT annotation for Amplitude-specific metadata

## Product Ecosystem Integration

Warehouse-native Amplitude fits into the broader Amplitude ecosystem as an alternative data source approach. While traditional Amplitude implementations require event data ingestion into Amplitude's systems, WNA maintains data within the customer's Snowflake environment.

### Relationship to Core Amplitude
- Uses the same analytical interface and capabilities
- Provides the same types of insights and visualizations
- Differs primarily in data storage location and access method

### Limitations
WNA has some feature limitations compared to standard Amplitude:
- Some advanced features may not be supported
- Performance depends on Snowflake optimization
- Formula constraints may apply to certain analyses

## Technical Implementation

### Snowflake Connection Requirements
- Read-only credentials for Amplitude access
- Properly configured clustering keys for performance
- Appropriate schema design (star or snowflake)

### Model Creation Methods

#### Direct Table Selection
```
SELECT * FROM your_snowflake_table
```

#### SQL Query Approach
Custom SQL queries can be used to transform data before analysis.

#### Bulk Model Management (YAML)
```yaml
models:
  - name: "event_model_name"
    type: "EVENT"
    config:
      type: "TABLE"
      table: "your_event_table"
    fieldMapping:
      event_time: "timestamp_column"
      user_id: "user_identifier_column"
      event_type: "event_name_column"
```

#### DBT Integration
DBT models can be annotated with Amplitude metadata:
```sql
-- In your DBT model
{{ config(
    materialized='table',
    amplitude_meta={
        "data_models": [{
            "type": "EVENT",
            "special_columns": {
                "event_time": "timestamp_column",
                "user_id": "user_identifier_column"
            }
        }]
    }
) }}
```

### Performance Optimization
- Use appropriate clustering keys based on query patterns
- Implement partitioning strategies for large datasets
- Consider cardinality when selecting clustering keys
- Choose between star and snowflake schema based on data complexity