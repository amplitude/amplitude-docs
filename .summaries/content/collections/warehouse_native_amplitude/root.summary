Warehouse-native Amplitude (WNA) is a data analytics platform that enables organizations to perform Amplitude's behavioral analytics directly on their Snowflake data warehouse infrastructure without data ingestion requirements. This architecture preserves data sovereignty while providing access to Amplitude's analytics capabilities through read-only warehouse connections.

## Product Architecture and Feature Relationships

WNA establishes direct, read-only connections to Snowflake data warehouses with a one-to-one mapping between Amplitude projects and warehouse connections. The platform provides three distinct interfaces for data model management:

**Manual Data Model Creation** operates through Amplitude's user interface, offering Table Selection and SQL Query options for building individual warehouse-native data models. This interface supports all six core data model types with mandatory field requirements including unique IDs, timestamps, and type-specific attributes.

**Bulk Model Management** utilizes YAML-based configuration systems for batch operations across multiple data models. The system employs DataModel objects with tableConfig or sqlConfig specifications, enabling efficient large-scale deployments while maintaining the same data type support as manual creation.

**DBT Integration** connects with existing Data Build Tool workflows through manifest file annotations using `amplitude_meta` metadata configuration. This integration allows data teams to manage Amplitude models within established DBT infrastructure while supporting all core data model types through specialized column mapping strategies.

## Key Nomenclature and Definitions

**Data Model Types** encompass six distinct categories:
- **EVENT**: Fact table events requiring event_time, unique_id, and event_type fields
- **EVENT_PROPERTIES**: Additional event-associated attributes requiring eventJoinField configuration
- **CURRENT_USER_PROPERTIES**: Present-state user attributes
- **HISTORICAL_USER_PROPERTIES**: Time-series user attribute data with startTime and endTime requirements
- **CURRENT_GROUP_PROPERTIES**: Present-state group-level attributes
- **HISTORICAL_GROUP_PROPERTIES**: Time-series group attribute data

**Schema Patterns** support both star schema architectures (centralized fact tables with dimension tables) and snowflake schema approaches (normalized dimension tables) with specific optimization recommendations for analytical workloads.

**Clustering and Partitioning** strategies include clustering keys with LINEAR() function support for event time optimization, composite clustering keys for high cardinality columns, and table partitioning for enhanced query execution performance.

**Identity Spaces** provide user identification frameworks mapping different user identifiers across data models, supporting Monthly Tracked Users (MTU) counting and comprehensive user journey analysis.

## Product Ecosystem Integration

WNA integrates into Amplitude's broader analytics ecosystem while maintaining warehouse-native independence. The platform generates and executes queries directly against Snowflake infrastructure, requiring service account configuration with read-only credentials and optimized clustering key implementation.

The system supports core Amplitude analytics capabilities with specific constraints:
- Formula limitations affecting HIST, PERCENTILE, ROLLWINBEFORE, CUMSUM, ACTIVE, and ARPAU functions
- Restricted functionality in event segmentation, funnel analysis, retention analysis, cohort segmentation, and journey analysis
- Single connection limitation per Amplitude project

## Technical Implementation

**Configuration Management** employs YAML-based configuration files structured with apiVersion, metadata, and spec sections for bulk operations. DBT integration leverages manifest file parsing with amplitude_meta annotations for seamless model configuration within existing data workflows.

**Data Modeling Patterns** support two primary approaches:
- **One event per table**: Dedicated table structures for individual event types
- **Multiple events per table**: Consolidated tables containing multiple event types with event_type field differentiation

**Required Field Configuration** mandates specific field mappings across all models:
- **eventTime**: TIMESTAMP_NTZ format requirement
- **userId** and **groupId**: Identity mapping fields
- **eventId**: Unique event identification
- **Historical models**: Additional startTime and endTime field requirements
- **Event properties**: eventJoinField configuration for relationship mapping

**Performance Optimization** emphasizes strategic clustering key selection, particularly LINEAR() function implementation for time-based clustering, composite key strategies for high cardinality scenarios, and schema design pattern optimization to balance analytical workload performance with data storage efficiency requirements.