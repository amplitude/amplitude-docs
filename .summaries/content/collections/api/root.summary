# Amplitude Analytics API Suite

Amplitude is a comprehensive product analytics platform that provides enterprise-scale event tracking, user behavior analysis, and data management capabilities. The platform enables organizations to collect, process, and analyze user interaction data across web, mobile, and server-side applications through a robust suite of APIs and integrations.

## Product Architecture and Feature Relationships

The Amplitude ecosystem is structured around four primary functional layers that work together to provide end-to-end analytics capabilities:

**Data Ingestion Infrastructure** forms the foundation with the HTTP V2 API serving as the primary real-time event collection endpoint at `api2.amplitude.com/2/httpapi`, complemented by the Batch Event Upload API for high-volume scenarios supporting up to 20MB payloads. The Attribution API specifically handles mobile advertising attribution data using platform-specific identifiers like IDFA and Android App Set ID.

**Identity and User Management** operates through the Identify API for user property management without event generation, the Group Identify API for organization-level properties via the Accounts add-on, and the User Mapping API enabling cross-project user aliasing through the Portfolio add-on. This layer maintains the critical user identity graph that connects anonymous device interactions to known user profiles.

**Data Access and Analytics** provides programmatic access to collected data through the Export API for bulk event extraction in zipped JSON format, the Dashboard REST API for accessing pre-computed analytics results including funnels and retention analysis, and the User Profile API for retrieving comprehensive user profiles with computed properties and behavioral recommendations.

**Governance and Compliance** ensures data privacy and regulatory compliance through the User Privacy API for GDPR/CCPA deletion requests, the CCPA DSAR API for asynchronous data subject access requests, and the Taxonomy API for Enterprise users to manage event schemas and tracking plans.

## Core Nomenclature and Technical Definitions

**Identity Management:**
- `user_id`: Business-defined identifier linking events to known users
- `device_id`: Anonymous device-specific identifier for pre-authentication tracking
- `amplitude_id`: Internal platform identifier automatically assigned to users
- `insert_id`: Deduplication key preventing duplicate event processing
- `session_id`: Temporal grouping identifier for user interaction sessions

**Event Data Structure:**
- `event_type`: Categorical name describing the user action
- `event_properties`: Action-specific metadata and context
- `user_properties`: Persistent user-level attributes and characteristics
- `group_properties`: Organization or account-level attributes (requires Accounts add-on)
- `server_upload_time`: UTC ISO-8601 timestamp of server receipt

**Property Manipulation Operations:**
- `$set`: Assign or update property values
- `$setOnce`: Initialize properties only if not previously defined
- `$add`: Increment numeric properties
- `$append`/`$prepend`: Add elements to array properties
- `$unset`: Remove properties entirely
- `$remove`: Remove specific elements from arrays

**Authentication Mechanisms:**
- `api_key`: Project-level authentication for data ingestion
- HTTP Basic Authentication: Username/password for analytical data access
- Secret keys: Server-side authentication for user profile operations
- SCIM keys: Identity provider integration authentication

## Broader Product Ecosystem Integration

Amplitude functions as a central analytics hub with extensive integration capabilities across the modern data stack. The platform ingests data from multiple sources including server-to-server implementations, mobile and web SDKs, and third-party platforms identified through partner_id parameters.

**Data Flow Architecture** supports bidirectional data movement with event streaming to external systems including delivery metrics monitoring, cohort synchronization to marketing automation platforms, and warehouse exports for data lake integration.

**Identity Resolution** operates through SCIM 2.0 integration with enterprise identity providers like Okta and JumpCloud, cross-project user mapping via the Portfolio add-on, and mobile attribution matching with configurable 72-hour attribution windows.

**Compliance Infrastructure** provides automated data deletion workflows, comprehensive data subject access request processing, and regional data residency options with dedicated EU endpoints for GDPR compliance.

## API Endpoints and Technical Implementation

**Core Data Ingestion:**
- `POST api2.amplitude.com/2/httpapi` - Primary real-time event ingestion
- `POST api2.amplitude.com/batch` - Bulk event upload for high-volume scenarios
- `POST api2.amplitude.com/attribution` - Mobile attribution event processing
- `POST api2.amplitude.com/identify` - User property updates without event generation
- `POST api2.amplitude.com/groupidentify` - Group-level property management

**Analytics and Data Retrieval:**
- `GET api/2/export` - Bulk event data extraction
- `GET profile-api.amplitude.com/v1/userprofile` - Individual user profile retrieval
- `GET api/3/cohorts` - Behavioral cohort management
- `GET data-api.amplitude.com/api/3/lookup_table` - CSV-based property enrichment

**Platform Management:**
- `POST api/2/release` - Release milestone annotations
- `POST api/2/annotations` - Chart and dashboard annotations
- `POST api/2/deletions/users` - Privacy-compliant user data deletion
- `GET core.amplitude.com/scim/1/` - Enterprise user provisioning

**Operational Constraints and Limits:**
The platform enforces comprehensive rate limiting with 1000 events/second per device/user and 500K events/day limits, user property updates capped at 1800/hour per user, cohort downloads limited to 500 requests/month for Growth/Enterprise tiers, and Profile API access limited to 600 requests/minute. Payload constraints include 20MB for batch uploads, 1MB for HTTP V2 requests, and 100MB for lookup table operations.

The system provides robust error handling with standard HTTP status codes (400, 413, 429, 503) and comprehensive monitoring through delivery metrics and real-time streaming analytics, supporting both standard and EU data residency requirements through region-specific endpoint infrastructure.