Amplitude Experiment is a comprehensive feature flagging and A/B testing platform that provides both remote and local evaluation capabilities for running controlled experiments and managing feature rollouts. The system is built on a robust architecture leveraging Fastly CDN and AWS services to deliver high-performance experimentation at scale.

## Core Architecture and Performance

The platform operates on a distributed architecture using Fastly CDN for global content delivery, AWS Application Load Balancer for traffic routing, and DynamoDB for experiment configuration storage. The system supports two primary evaluation modes:

- **Remote Evaluation**: Utilizes CDN caching with 60-minute TTL, delivering sub-100ms latency globally with cache hit rates exceeding 95%
- **Local Evaluation**: Enables client-side processing with pre-fetched flag configurations, supporting microsecond-level evaluation times

Performance is optimized through client-side SDK caching, local defaults implementation, and behavioral cohorts computed hourly. The identity resolution system maintains user metadata stores to support dynamic targeting based on user properties.

## Experimentation and Randomization

Amplitude Experiment employs a sophisticated deterministic randomization system using murmur3 hash algorithms. The process involves:

1. **Hash Generation**: Creates murmur3_x86_32 hash of "bucketingSalt/amplitude_id"
2. **Two-Stage Assignment**: 
   - First stage determines experiment inclusion via mod 100 against percentage rollout
   - Second stage assigns variants using floor division with weighted ranges (0-42949672)

This deterministic approach ensures consistent user experiences across sessions while maintaining statistical validity.

## Flag Dependencies and Relationships

The system supports complex flag relationships through three dependency types:

- **Flag Prerequisites**: Define evaluation order where dependent flags require parent flags to be active
- **Mutual Exclusion Groups**: Prevent users from being assigned to multiple conflicting experiments simultaneously
- **Holdout Groups**: Reserve traffic percentages for control analysis and baseline comparisons

These dependencies enable sophisticated experiment slot management and traffic allocation strategies while maintaining proper holdout analysis capabilities.

## Event Tracking and Analytics

Amplitude Experiment implements comprehensive event tracking through two primary event types:

- **Assignment Events** (`[Experiment] Assignment`): Track when users are assigned to experiment variants
- **Exposure Events** (`$exposure` or `[Experiment] Exposure`): Record when users actually experience the experiment

The system automatically tracks assignments through `fetch()` calls in remote evaluation and `evaluate()`/`variant()` calls in local evaluation. Experiment user properties are formatted as `[Experiment] <flag_key>` and support automatic exposure tracking with insert_id deduplication.

## Statistical Analysis Framework

The platform employs advanced statistical methodologies including:

- **Sequential Testing**: Uses mixture sequential probability ratio test (mSPRT) for continuous statistical inference
- **Early Stopping**: Enables valid results at any viewing time without predetermined sample sizes
- **Multi-Metric Analysis**: Supports both binary and continuous metrics using Central Limit Theorem principles

Analysis calculations process exposure events (E), metric events (M, T), property values (S, A), and funnel events (FM, FT) chronologically to generate unique conversions, event totals, property value sums/averages, and funnel conversion metrics.

## Key API Methods and SDK Integration

Primary SDK methods include:
- `fetch()`: Remote evaluation with automatic assignment tracking
- `evaluate()`: Local evaluation for single flag assessment  
- `variant()`: Local evaluation with exposure event generation

The system maintains SDK compatibility matrices across multiple platforms (Node.js, Go, JVM) with specific minimum versions required for flag dependencies support in local evaluation mode.

## Caching and Dynamic Targeting

The CDN caching system operates with sophisticated cache invalidation triggered by deployment updates and configuration changes. Dynamic targeting capabilities include:

- User property-based targeting with real-time evaluation
- Behavioral cohorts with hourly computation cycles
- Geographic routing optimization (us-west-2, eu-central-1)

Cache keys incorporate user information to ensure personalized experiment delivery while maintaining high cache hit rates for optimal performance.