## Amplitude Experiment

Amplitude Experiment is a comprehensive feature flagging and A/B testing platform built on a high-performance architecture using Fastly CDN and AWS services. The platform provides both remote and local evaluation modes for running experiments and managing feature flags, with sophisticated statistical analysis capabilities and enterprise-scale performance optimization.

## Product Architecture and Feature Relationships

The platform operates through two primary evaluation modes that work together to provide flexible experimentation capabilities:

**Remote Evaluation** leverages Fastly CDN for global distribution with 60-minute TTL caching, providing low-latency flag evaluation through the `fetch()` method. This mode automatically handles assignment tracking and integrates with Amplitude's identity resolution system and user metadata store.

**Local Evaluation** enables client-side processing through SDKs (Node.js, Ruby, JVM, Go, Python, PHP) using the `evaluate()` method, with pre-fetched flag configurations stored locally. This mode supports advanced features like flag dependencies and provides superior performance for high-volume applications.

**Flag Dependencies** create sophisticated relationships between flags, enabling prerequisites, mutual exclusion groups, and holdout groups. These dependencies define evaluation order and allow for complex experimental designs where flags can influence each other's behavior.

## Key Nomenclature and Definitions

**Event Tracking System:**
- `[Experiment] Assignment` events: Track when users are assigned to experiment variants
- `$exposure` / `[Experiment] Exposure` events: Track when users actually see experiment variants
- `[Experiment] <flag_key>` format: User properties storing experiment assignments
- Monthly Tracked Users (MTU): Billing metric based on exposure events

**Randomization Components:**
- **Bucketing Salt**: Unique identifier combined with amplitude_id for deterministic assignment
- **Two-stage Bucketing**: First determines experiment inclusion via mod 100 against percentage rollout, then assigns variants through floor division with weighted ranges 0-42949672
- **Murmur3 Hash**: Deterministic randomization algorithm using murmur3_x86_32 of "bucketingSalt/amplitude_id"

**Statistical Analysis:**
- **mSPRT (mixture Sequential Probability Ratio Test)**: Advanced statistical method enabling early experiment termination without predetermined sample sizes
- **Exposure Events (E)**, **Metric Events (M, T)**, **Property Values (S, A)**, **Funnel Events (FM, FT)**: Variables used in experiment analysis chart calculations

## Broader Product Ecosystem Integration

Amplitude Experiment integrates deeply with the Amplitude Analytics ecosystem through several key touchpoints:

**Data Infrastructure**: Experiment data flows into Amplitude Analytics for comprehensive analysis, with exposure events contributing to MTU billing calculations and user journey analysis.

**Identity Resolution**: Leverages Amplitude's identity resolution system to maintain consistent user experiences across devices and sessions, ensuring accurate experiment assignment and tracking.

**Behavioral Cohorts**: Integrates with Amplitude's behavioral cohort system for dynamic targeting, with hourly cohort computation affecting cache performance and targeting accuracy.

**Performance Architecture**: Built on AWS Application Load Balancer and DynamoDB for experiment storage, with Fastly CDN providing global distribution and caching capabilities.

## API Endpoints and Technical Implementation

**Core SDK Methods:**
- `fetch()`: Remote evaluation method for retrieving experiment assignments
- `evaluate()`: Local evaluation method for client-side flag processing
- `variant()`: Method for accessing specific variant configurations

**Performance Optimization:**
- Geographic latency benchmarks across regions (us-west-2, eu-central-1)
- Cache hit/miss performance monitoring through Fastly CDN
- Client-side caching with local storage for experiment variants
- Network call optimization through local defaults implementation

**Analysis Calculations:**
The platform processes chronological event sequences to calculate unique conversions, event totals, property value calculations, and funnel conversions using specific mathematical formulas that account for user exposure tracking and metric event relationships.

**Dynamic Targeting Considerations:**
Cache behavior adapts based on targeting criteria, with user properties and behavioral cohorts affecting cache staleness and invalidation patterns. Deployment-based cache invalidation ensures consistency across flag configuration updates.