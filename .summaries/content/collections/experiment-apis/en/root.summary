Amplitude Experiment is a comprehensive feature flagging and experimentation platform that enables teams to manage feature rollouts, A/B tests, and controlled experiments through both evaluation and management APIs. The platform supports both remote and local evaluation modes, allowing flexibility in how feature flags and experiments are delivered to applications.

## Product Architecture and Feature Relationships

The Amplitude Experiment ecosystem consists of two primary API layers:

**Evaluation API** serves as the runtime engine, providing real-time variant assignments through the `/v1/vardata` endpoint for remote evaluation and flag configuration downloads via `/v1/flags` for local evaluation. This API uses deployment key authentication and supports regional deployments across US (`api.lab.amplitude.com`) and EU (`api.lab.eu.amplitude.com`) servers.

**Management API** provides comprehensive administrative control over the experimentation infrastructure through six core endpoint categories: flags, experiments, mutex groups, holdouts, deployments, and versions. This API uses management API key authentication with Bearer token authorization and enforces rate limiting at 100 requests per second with 100,000 daily limits.

The platform's traffic allocation system operates through a hierarchical structure where **mutex groups** manage experiment traffic allocation using slot-based assignment, preventing traffic overlap between competing experiments. **Holdout groups** enable control group management by excluding specified user percentages from all experiments, supporting statistical validity. **Deployments** serve as assignment targets that both experiments and flags can be deployed to, supporting client and server deployment types.

## Key Nomenclature and Definitions

**Bucketing Configuration**: Core mechanism for user assignment using `bucketingKey` (typically `amplitude_id`), `bucketingSalt` for randomization, and `rolloutPercentage` for traffic control. Supports sticky bucketing to ensure consistent user experiences across sessions.

**Evaluation Modes**: 
- **Remote evaluation**: Real-time API calls to retrieve variant assignments
- **Local evaluation**: Client-side evaluation using downloaded flag configurations

**Experiment States**: Lifecycle management through planning, running, and decision-made states, with decisions including rollout, rollback, or continue-running options.

**Variant Management**: Each experiment or flag contains multiple variants with configurable payloads, rollout weights, and targeting segments. Supports individual user inclusions/exclusions with limits of 500 variant inclusions.

**Target Segments**: Advanced targeting capabilities using segment conditions, cohort targeting, and individual user targeting for precise audience control.

## Broader Product Ecosystem Integration

Amplitude Experiment integrates deeply with the broader Amplitude analytics ecosystem through automatic event tracking. The platform generates `[Experiment] Assignment` events when the `X-Amp-Exp-Track` header is included, enabling seamless integration with Amplitude's analytics and behavioral tracking capabilities.

The versioning system maintains complete audit trails of flag and experiment configurations through the `/api/1/versions` endpoint, supporting time-based filtering and cursor pagination for historical analysis. This enables teams to track configuration changes and their impact on user behavior through Amplitude's analytics platform.

## API Endpoints and Technical Implementation

**Primary Evaluation Endpoints**:
- `GET /v1/vardata` - Retrieve variant assignments with user context
- `GET /v1/flags` - Download flag configurations for local evaluation

**Management API Structure**:
- `/api/1/deployments` - Deployment CRUD operations
- `/api/1/experiments` - Experiment lifecycle management  
- `/api/1/flags` - Feature flag operations
- `/api/1/holdouts` - Holdout group management
- `/api/1/mutexs` - Mutex group traffic allocation
- `/api/1/versions` - Configuration version history

Authentication follows a dual-key approach: deployment keys for evaluation APIs and management API keys for administrative operations. The platform supports cursor-based pagination across all list endpoints using `nextCursor` parameters, ensuring efficient data retrieval for large-scale implementations.

Regional deployment support includes dedicated EU residency servers for compliance requirements, while maintaining feature parity across geographic regions. The platform's architecture supports both real-time experimentation needs and comprehensive administrative control, making it suitable for enterprise-scale feature management and experimentation programs.