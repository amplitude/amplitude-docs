# Amplitude Experiment Product Overview

Amplitude Experiment is a feature experimentation and feature flag management platform that enables product teams to test new features, control feature rollouts, and make data-driven decisions. The platform provides capabilities for creating and managing experiments, feature flags, deployments, holdout groups, and mutex groups through both UI and API interfaces.

## Key Features and Concepts

### Core Components

1. **Feature Flags**: Toggle features on/off or serve different variants to different users.
2. **Experiments**: Controlled tests that compare different variants of a feature to measure impact.
3. **Deployments**: Environments where experiments or flags can be assigned (client-side or server-side).
4. **Holdout Groups**: Control groups kept out of experiments to measure long-term effects.
5. **Mutex Groups**: Groups that ensure users are only included in one experiment at a time from a set of experiments.
6. **Variants**: Different versions of a feature being tested in an experiment.

### Evaluation Methods

1. **Remote Evaluation**: Server-side evaluation of variant assignments via API calls.
2. **Local Evaluation**: Client-side evaluation using SDKs.
3. **Sticky Bucketing**: Ensures users consistently receive the same variant.

### User Targeting

1. **Individual Inclusions/Exclusions**: Explicitly include or exclude specific users.
2. **Target Segments**: Define user groups based on properties.
3. **Rollout Percentages**: Control the percentage of users who receive a variant.

## Product Relationships and Architecture

Amplitude Experiment integrates with the broader Amplitude ecosystem, particularly with Amplitude Analytics for tracking experiment results. The platform is structured around:

1. **Management Layer**: APIs for creating and configuring experiments, flags, etc.
2. **Evaluation Layer**: APIs and SDKs for determining which variant a user should receive.
3. **Deployment Environments**: Separate configurations for different environments (development, staging, production).

The system supports both client-side implementations (web, mobile) and server-side implementations through dedicated SDKs and APIs.

## Key Nomenclature and Definitions

- **Deployment Key**: Unique identifier for a deployment environment.
- **Flag Keys**: Identifiers for feature flags.
- **Bucketing Key**: Property used to determine variant assignment (e.g., user_id, device_id).
- **Evaluation Mode**: How variants are assigned (local or remote).
- **Bucketingsalt**: Value that ensures consistent bucketing across experiments.
- **Slots**: Divisions within mutex groups that control traffic allocation.
- **Rollout Weights**: Percentage distribution of traffic to different variants.
- **Management API Key**: Authentication credential for the Management API.

## API Structure

### Experiment Management API

Base endpoints with regional variations (US, EU):
- US: `https://management-api.experiment.amplitude.com`
- EU: `https://management-api.experiment.eu.amplitude.com`

Key endpoint groups:
1. **Flag Endpoints**: `/flags` - Create, list, edit flags and manage variants
2. **Experiment Endpoints**: `/experiments` - Manage experiments and their configurations
3. **Deployment Endpoints**: `/deployments` - Manage deployment environments
4. **Holdout Group Endpoints**: `/holdouts` - Configure control groups
5. **Mutex Group Endpoints**: `/mutexs` - Manage mutual exclusion groups
6. **Version Endpoints**: `/versions` - Retrieve version history

### Experiment Evaluation API

Endpoint: `https://api.lab.amplitude.com/v1/vardata`

Parameters:
- `deployment_key`: Identifies the deployment
- `flag_keys`: Comma-separated list of flags to evaluate
- `user_id` or `device_id`: User identifier
- `context`: Additional user properties for targeting

Headers:
- `X-Amp-Exp-Track`: Controls whether to track assignment events (default: true)
- `Authorization`: API key for authentication

## Implementation Patterns

1. **Remote Evaluation Flow**:
   - Send user context to Evaluation API
   - Receive variant assignments
   - Apply variants in application
   - Track exposure events

2. **CDN Caching**:
   - Pass user information as query parameters
   - Enable caching of common variant assignments

3. **Experiment Configuration**:
   - Create deployments for different environments
   - Configure experiments with variants and targeting rules
   - Set up holdouts for measuring long-term effects
   - Use mutex groups to prevent experiment interference

The platform supports pagination through cursor-based mechanisms and implements rate limiting to ensure API stability.