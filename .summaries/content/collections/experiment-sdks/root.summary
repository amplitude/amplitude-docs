# Amplitude Experiment SDK Suite

Amplitude Experiment is a comprehensive feature flagging and experimentation platform that provides SDKs across multiple programming languages and platforms for both client-side and server-side implementations. The platform enables developers to implement feature flags, conduct A/B tests, and manage feature rollouts with sophisticated targeting capabilities including user properties, device characteristics, and cohort-based segmentation.

## Product Architecture and Relationships

The Experiment SDK ecosystem is structured around two primary evaluation modes:

**Remote Evaluation**: Client applications make API calls to Amplitude's servers to fetch experiment variants for users. This approach is typically used for client-side implementations where flag configurations are retrieved on-demand via `fetch()` methods.

**Local Evaluation**: Flag configurations are downloaded and cached locally, enabling client-side evaluation without network calls for each flag check. This mode uses `start()` methods to initialize local flag configs and `evaluate()` methods for variant determination.

The **Experiment Evaluation Proxy** serves as a bridge component, enabling local evaluation capabilities on platforms that don't natively support it by providing a stateless service that exposes remote evaluation APIs while maintaining local evaluation performance characteristics.

## Key Nomenclature and Definitions

**Deployment Key**: Authentication credential that identifies a specific experiment deployment environment, used during SDK initialization across all platforms.

**Variants**: The different versions or treatments that users can be assigned to within an experiment, accessed via `variant()` methods using flag keys.

**Flag Key**: Unique identifier for a specific feature flag or experiment, used to retrieve variant assignments.

**ExperimentUser**: User object containing identification and properties (user_id, device_id, user_properties, group_properties) used for targeting and bucketing decisions.

**Exposure Tracking**: Automatic or manual tracking of when users are exposed to experiment variants, typically integrated with analytics platforms for measurement.

**Cohort Targeting**: Advanced targeting capability that allows experiments to target users based on behavioral cohorts defined in Amplitude Analytics, with hourly sync intervals.

**Bootstrapping**: Initialization technique using `initialVariants` or `Source.InitialVariants` to provide fallback flag configurations, particularly useful for server-side rendering scenarios.

**Assignment Tracking**: Automatic logging of experiment assignments to analytics platforms with 24-hour deduplication to prevent duplicate events.

## Platform-Specific Implementations

**Client-Side SDKs** (Android, iOS, JavaScript, React Native): Focus on remote evaluation with `fetch()` methods, support Amplitude Analytics integration via `initializeWithAmplitudeAnalytics()`, and provide automatic exposure tracking. These SDKs also support local evaluation modes with `start()` methods for improved performance.

**Server-Side SDKs** (Go, JVM/Java/Kotlin, Node.js, PHP, Python, Ruby): Emphasize both remote and local evaluation modes, with local evaluation featuring flag configuration polling/streaming, cohort sync capabilities, and assignment tracking. Server-side SDKs use `fetchV2()`/`evaluateV2()` methods for enhanced functionality.

**Legacy/Maintenance SDKs**: The React Native Legacy SDK represents deprecated implementations maintained for backward compatibility but not recommended for new implementations.

## Integration Ecosystem

The platform integrates extensively with analytics providers:
- **Amplitude Analytics**: Native integration with automatic user synchronization and exposure tracking
- **Third-party Analytics**: Support for Segment, mParticle, and custom analytics providers via provider interfaces
- **Amplitude Cookie Integration**: Device ID synchronization using `AmplitudeCookie` parsing for consistent user identification

## Configuration and Deployment

**Server Zones**: Support for US (`ServerZone.US`) and EU (`ServerZone.EU`) data centers for data residency compliance.

**Evaluation Proxy Deployment**: Docker/Kubernetes deployment on port 3546 with Redis storage backend for cohort data and assignment deduplication.

**Configuration Options**: Extensive configuration including timeout settings (`fetchTimeoutMillis`), retry policies (`fetchRetries`), polling intervals (`flagConfigPollingIntervalMillis`), and streaming updates (`streamUpdates`).

## API Endpoints and Methods

**Core Evaluation Methods**:
- `fetch()`/`fetchV2()`: Remote variant retrieval
- `start()`: Local evaluation initialization  
- `evaluate()`/`evaluateV2()`: Local variant evaluation
- `variant(flagKey)`: Variant access with automatic exposure tracking

**Configuration Methods**:
- `initializeWithAmplitudeAnalytics()`: Amplitude-integrated initialization
- `refreshFlagConfigs()`: Manual flag configuration refresh
- Provider interfaces: `ExperimentUserProvider`, `ExposureTrackingProvider`, `AssignmentTrackingProvider`

**Installation Commands**:
- npm: `@amplitude/experiment-js-client`, `@amplitude/experiment-node-server`
- Maven/Gradle: `com.amplitude:experiment-jvm-server`
- CocoaPods: `AmplitudeExperiment`
- pip: `amplitude-experiment`
- gem: `amplitude-experiment`

The platform supports sophisticated targeting including account-level bucketing, group properties evaluation, and large-scale cohort targeting with automatic synchronization, making it suitable for enterprise-scale experimentation and feature management workflows.