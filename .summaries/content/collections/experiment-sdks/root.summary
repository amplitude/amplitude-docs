# Amplitude Experiment SDK Suite

Amplitude Experiment is a comprehensive feature flagging and experimentation platform that provides client-side and server-side SDKs across multiple programming languages and platforms. The platform enables developers to implement feature flags, conduct A/B tests, and manage feature rollouts with sophisticated targeting capabilities including user properties, device characteristics, and cohort-based segmentation.

## Product Architecture and Evaluation Models

The Amplitude Experiment ecosystem operates on two primary evaluation models:

**Remote Evaluation**: SDKs fetch pre-computed variant assignments from Amplitude's servers via API calls. This approach ensures consistency across platforms but requires network connectivity and introduces latency. Remote evaluation uses deployment keys for authentication and typically involves `fetch()` or `fetchV2()` methods to retrieve variants for specific users.

**Local Evaluation**: SDKs download flag configurations and evaluate variants client-side, enabling faster response times and offline capability. Local evaluation requires periodic syncing of flag configurations and cohort data, using methods like `start()`, `evaluate()`, or `evaluateV2()`. This model supports real-time flag streaming and automatic configuration polling.

The **Evaluation Proxy** serves as a bridge solution, enabling local evaluation capabilities on unsupported platforms through a Docker-based service that handles assignment tracking, cohort syncing, and provides a standardized API interface.

## Platform Coverage and SDK Relationships

The SDK suite provides comprehensive platform coverage:

**Client-Side SDKs**: JavaScript, React Native, iOS (Swift), Android (Kotlin/Java), and legacy React Native implementations focus on user-facing applications with automatic exposure tracking and analytics integration.

**Server-Side SDKs**: Node.js, Python, Ruby, PHP, JVM (Java/Kotlin), and Go implementations designed for backend services with enhanced security, cohort targeting, and bulk evaluation capabilities.

**Cross-Platform Solutions**: React Native SDK supports both iOS and Android with shared configuration, while the Evaluation Proxy enables local evaluation on any platform via HTTP API.

## Key Nomenclature and Concepts

**Deployment Key**: Authentication credential that identifies the experiment environment and determines available flag configurations. Different keys are used for development, staging, and production environments.

**Flag Key**: Unique identifier for individual feature flags within an experiment configuration.

**Variant**: The evaluated result of a flag for a specific user, containing a value (string, boolean, number, or JSON) and optional payload data.

**ExperimentUser**: User context object containing identification (user_id, device_id), properties (user_properties, group_properties), and targeting attributes used for flag evaluation.

**Exposure Tracking**: Automatic or manual recording of when users are exposed to specific flag variants, essential for experiment analysis and statistical validity.

**Cohort Targeting**: Advanced segmentation capability that allows flags to target predefined user groups synced from Amplitude Analytics or external sources.

**Bootstrapping**: Technique for providing initial flag configurations or variants to reduce latency and enable server-side rendering (SSR) scenarios.

## Integration Ecosystem

Amplitude Experiment integrates deeply with the broader Amplitude ecosystem and third-party analytics platforms:

**Amplitude Analytics Integration**: Native integration using `initializeWithAmplitudeAnalytics()` provides automatic user context sharing, device ID synchronization via AmplitudeCookie parsing, and seamless exposure event tracking.

**Third-Party Analytics**: Support for Segment, mParticle, and custom analytics providers through ExposureTrackingProvider interfaces and user provider abstractions.

**Infrastructure Integration**: Kubernetes Helm charts for Evaluation Proxy deployment, Redis support for persistent storage and deduplication, and Docker containerization for scalable deployments.

## API Patterns and Configuration

Common API patterns across SDKs include:

**Initialization Methods**:
- `initializeRemote(deploymentKey)` / `initializeLocal(deploymentKey)`
- `initializeWithAmplitudeAnalytics(apiKey, config)`

**Evaluation Methods**:
- `fetch()` / `fetchV2()` for remote evaluation
- `start()` followed by `evaluate()` / `evaluateV2()` for local evaluation
- `variant(flagKey)` for accessing specific flag values

**Configuration Options**:
- `fetchTimeoutMillis`, `fetchRetries` for network resilience
- `flagConfigPollingIntervalMillis` for local evaluation sync frequency
- `automaticExposureTracking`, `fetchOnStart`, `pollOnStart` for behavioral control
- `serverZone` for EU data residency compliance
- `cohortSyncConfig` for advanced targeting capabilities

**Management APIs**: Server-side SDKs support management API keys for dynamic flag configuration updates and deployment automation.

The platform supports account-level bucketing through group properties, automatic assignment tracking with 24-hour deduplication, and provides fallback mechanisms for network failures or missing configurations. Advanced features include real-time flag streaming, cohort sync with hourly updates, and comprehensive logging interfaces for debugging and monitoring.