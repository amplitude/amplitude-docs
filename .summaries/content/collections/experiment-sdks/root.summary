# Amplitude Experiment: Feature Flag and Experimentation Platform

## Overview

Amplitude Experiment is a feature flag and experimentation platform that enables product teams to safely deploy features, run A/B tests, and deliver personalized user experiences. The platform provides a unified solution for feature management and experimentation across client and server environments with support for multiple programming languages and frameworks.

Key features include:
- Feature flag management with gradual rollouts and kill switches
- A/B/n testing with statistical analysis
- Targeting capabilities for specific user segments
- Dual evaluation modes (remote and local) for different performance needs
- Cross-platform user consistency through account-level bucketing
- Real-time flag updates via streaming
- Automatic exposure tracking for analytics

## Product Architecture and Relationships

Amplitude Experiment consists of several interconnected components:

1. **Client SDKs**: Used in user-facing applications (web, mobile)
   - JavaScript/TypeScript
   - React Native
   - iOS (Swift)
   - Android (Kotlin/Java)

2. **Server SDKs**: Used in backend applications
   - Node.js
   - JVM (Java/Kotlin)
   - Python
   - Go
   - Ruby
   - PHP

3. **Evaluation Proxy**: A service that enables local evaluation within your infrastructure for platforms without native SDKs or for enhancing evaluation with large cohort targeting.

4. **Evaluation Modes**:
   - **Remote Evaluation**: Flag variants are determined server-side by Amplitude's services
   - **Local Evaluation**: Flag variants are determined within the client or server application using downloaded flag configurations

5. **Integration with Analytics**: Connects with Amplitude Analytics or third-party providers to track exposures and experiment results.

## Key Nomenclature and Definitions

- **Feature Flag**: A toggle that controls the visibility or behavior of a feature
- **Variant**: A specific version or configuration of a feature flag
- **Experiment**: A controlled test comparing different variants of a feature
- **ExperimentUser**: Object containing user properties used for targeting and bucketing
- **Deployment Key**: API key used to authenticate with Amplitude Experiment services
- **Server/Client Key**: Different types of deployment keys with varying security levels
- **Evaluation**: The process of determining which variant a user should receive
- **Exposure**: Event recorded when a user encounters a feature flag
- **Bucketing**: The process of consistently assigning users to variants
- **Cohort Targeting**: Directing specific variants to user segments based on properties
- **Flag Configuration**: The complete definition of a flag including rules, variants, and targeting
- **Bootstrap**: Pre-loading flag configurations for faster initial evaluation

## Integration with Amplitude Ecosystem

Amplitude Experiment integrates with the broader Amplitude product suite:

1. **Amplitude Analytics**: 
   - Automatic exposure tracking when integrated with Analytics SDKs
   - Experiment results analysis using Analytics user properties and events

2. **Amplitude Cohorts**: 
   - Target experiment variants to specific user segments defined in Amplitude
   - Use behavioral cohorts for sophisticated targeting

3. **Amplitude Dashboard**: 
   - Analyze experiment results and feature flag performance
   - Monitor flag usage and exposure metrics

The platform supports EU data residency requirements through server zone configuration options in the SDKs.

## Implementation Details

### Common SDK Patterns

All SDKs follow a similar implementation pattern:

1. **Initialization**:
   ```
   const client = Experiment.initialize(deploymentKey, {
     serverUrl: 'https://api.amplitude.com',
     fetchTimeoutMillis: 5000
   });
   ```

2. **User Identification**:
   ```
   const user = {
     user_id: 'user@example.com',
     device_id: 'device_id',
     user_properties: {
       premium: true
     }
   };
   ```

3. **Remote Evaluation**:
   ```
   await client.fetch(user);
   const variant = client.variant('flag-key', 'default-value');
   ```

4. **Local Evaluation**:
   ```
   await client.fetchEvaluationConfigs();
   const variant = client.evaluate(user, 'flag-key', 'default-value');
   ```

5. **Exposure Tracking**:
   ```
   client.exposure('flag-key', variant);
   ```

### Evaluation Proxy API

The Evaluation Proxy exposes RESTful endpoints:
- `POST /v1/evaluate` - Evaluate a user against all flags
- `POST /v1/evaluate/:flagKey` - Evaluate a user against a specific flag

The proxy can be deployed via Docker:
```
docker run -p 3000:3000 \
  -e AMPLITUDE_API_KEY=<deployment-key> \
  amplitude/experiment-evaluation-proxy
```

### Configuration Options

Common configuration parameters across SDKs:
- `serverUrl`: Custom server endpoint
- `serverZone`: Region selection (US or EU)
- `fetchTimeoutMillis`: Timeout for network requests
- `retryBackoff`: Retry configuration for failed requests
- `debug`: Enable debug logging
- `fallbackVariant`: Default variant when evaluation fails

The platform supports both online and offline modes, with capabilities for caching flag configurations for performance and reliability.