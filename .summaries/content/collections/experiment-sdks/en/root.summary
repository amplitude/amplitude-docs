# Amplitude Experiment: Feature Flag and Experimentation Platform

Amplitude Experiment is a comprehensive feature flag and experimentation platform that enables developers to implement feature flags, run A/B tests, and manage experiments across various platforms and programming languages. The platform supports both remote and local evaluation methods, allowing for flexible implementation based on specific use cases and performance requirements.

## Key Features and Concepts

1. **Feature Flags and Experiments**: Control feature rollouts, A/B testing, and experimentation across applications
2. **Remote Evaluation**: Server-side evaluation of flags and experiments
3. **Local Evaluation**: Client-side evaluation for improved performance and offline capabilities
4. **Exposure Tracking**: Automatic or manual tracking of feature flag exposures
5. **User Targeting**: Target specific users based on properties and cohorts
6. **Cohort Targeting**: Advanced targeting using Amplitude-defined cohorts
7. **Account-Level Bucketing**: Consistent experiences for users within the same account
8. **Analytics Integration**: Native integration with Amplitude Analytics and third-party providers
9. **Flag Streaming**: Real-time updates to flag configurations
10. **Assignment Tracking**: Track which users are assigned to which variants

## Product Ecosystem and Relationships

Amplitude Experiment consists of multiple SDKs for different platforms and an Evaluation Proxy service:

### Client-Side SDKs
- **JavaScript SDK**: For web applications
- **React Native SDK**: For cross-platform mobile applications
- **iOS SDK**: Native implementation for iOS applications
- **Android SDK**: Native implementation for Android applications

### Server-Side SDKs
- **Node.js SDK**: For Node.js applications
- **Python SDK**: For Python applications
- **Ruby SDK**: For Ruby applications
- **PHP SDK**: For PHP applications
- **JVM SDK**: For Java and Kotlin applications
- **Go SDK**: For Go applications

### Infrastructure Components
- **Evaluation Proxy**: A service that enables local evaluation within your infrastructure, supporting platforms without native SDKs

### Integration Points
- **Amplitude Analytics**: Native integration for tracking exposures and analyzing experiment results
- **Third-Party Analytics**: Support for integrating with other analytics providers
- **Cohort Sync**: Integration with Amplitude's user cohorts for advanced targeting

## Key Nomenclature and Definitions

- **Variant**: A specific version or configuration of a feature flag
- **Deployment Key**: API key used to authenticate SDK requests to Amplitude
- **ExperimentUser/User**: Object containing user properties used for targeting and evaluation
- **Exposure**: Event recorded when a user is exposed to a feature flag or experiment
- **Remote Evaluation**: Server-side evaluation of flags requiring network requests
- **Local Evaluation**: Client-side evaluation of flags without network requests
- **Flag Configuration**: Definition of a feature flag including rules, variants, and targeting
- **Cohort**: A group of users defined by specific criteria in Amplitude
- **Assignment**: The association of a user with a specific variant
- **Bucketing**: The process of consistently assigning users to variants

## Implementation Methods

### Remote Evaluation
Remote evaluation sends user properties to Amplitude's servers, which evaluate the flag rules and return the appropriate variants. This method:
- Supports all targeting capabilities
- Requires network connectivity
- Has higher latency due to network requests
- Is implemented via `fetch` or `fetchV2` methods in the SDKs

### Local Evaluation
Local evaluation downloads flag configurations to the client and evaluates them locally. This method:
- Provides faster evaluation with no network latency
- Works offline after initial configuration download
- Has limited targeting capabilities in some SDKs
- Is implemented via `evaluate` or `evaluateV2` methods in the SDKs

## API Endpoints and SDK Methods

### Common SDK Methods
- **initialize/init**: Set up the SDK with configuration options
- **fetch/fetchV2**: Fetch variants for a user via remote evaluation
- **evaluate/evaluateV2**: Evaluate variants for a user via local evaluation
- **variant**: Get a specific flag variant for a user
- **all**: Get all flag variants for a user
- **exposure/track**: Track exposure events manually

### Evaluation Proxy API
- **GET /v1/vardata**: Fetch flag configurations
- **POST /v1/evaluate**: Evaluate flags for a user
- **POST /v1/track**: Track assignment events

### Configuration Options
- **serverUrl**: API endpoint for Amplitude servers
- **serverZone**: Region for data storage (US or EU)
- **fetchTimeoutMillis**: Timeout for network requests
- **retryFetchOnFailure**: Whether to retry failed fetch requests
- **automaticExposureTracking**: Enable/disable automatic exposure tracking
- **flagConfigPollingIntervalMillis**: Interval for polling flag configurations
- **debug**: Enable debug logging

## Deployment and Infrastructure

The Evaluation Proxy can be deployed using:
- Docker containers
- Kubernetes with provided Helm charts
- Configuration via YAML files or environment variables
- Redis for persistent storage and deduplication

The SDKs can be integrated via standard package managers:
- npm/yarn for JavaScript and Node.js
- CocoaPods/Swift Package Manager for iOS
- Gradle for Android
- pip for Python
- gem for Ruby
- composer for PHP
- Maven/Gradle for JVM
- go modules for Go