## Amplitude Experiment Results

Amplitude Experiment Results is a comprehensive A/B testing analysis platform that enables teams to analyze experiments from both Amplitude's native experimentation tools and third-party or homegrown feature flagging platforms. The product provides statistical rigor through sequential testing methodologies and supports complex metric calculations to measure experiment impact across user behavior and business outcomes.

## Product Relationships and Features

The Experiment Results feature operates as a standalone analysis module within the broader Amplitude analytics ecosystem. It integrates with:

- **Third-party feature flagging platforms** through exposure event tracking
- **Amplitude's event tracking system** for metric calculation and user behavior analysis  
- **Primary Metric module** for defining and managing experiment success criteria
- **Amplitude's charting infrastructure** through the Experiment Results chart interface

The core workflow involves configuring exposure events that define when users are assigned to experiment variants, setting up metrics to measure experiment impact, and analyzing results through statistical testing frameworks.

## Key Nomenclature and Definitions

**Exposure Events**: Events that indicate when a user has been exposed to a specific experiment variant, serving as the foundation for experiment attribution and analysis.

**Exposure Attribution Window**: The time period during which user actions are attributed to their assigned experiment variant after initial exposure.

**Variant Configuration**: The setup of different experiment treatments, including the designation of control variants for baseline comparison.

**Metric Types**:
- **Unique Conversions**: Count of distinct users who performed a specific action
- **Event Totals**: Total count of events performed across all users
- **Sum/Average Property Value**: Aggregated numerical values from event properties
- **Funnel Conversion**: Multi-step conversion rate analysis
- **Formula Metrics**: Custom calculations combining multiple data points

**Sequential Testing**: A statistical methodology that allows for continuous monitoring of experiment results with controlled error rates, as opposed to traditional fixed-horizon T-tests.

**Cumulative Exposure**: The running total of users exposed to experiment variants over time.

## Formula Metrics System

The platform includes a sophisticated formula metrics engine supporting multiple functions:

- **UNIQUES**: Counts distinct users using HyperLogLog algorithm for scalability
- **TOTALS**: Aggregates event counts across users and time periods
- **PROPSUM/PROPAVG**: Calculates sum and average values of numerical event properties
- **PROPCOUNT/PROPMAX/PROPMIN**: Additional property-based aggregations
- **REVENUETOTAL**: Specialized revenue calculation function

Formula metrics support arithmetic operations and can combine multiple data sources, with statistical significance calculated through variance, covariance, and confidence interval computations.

## Broader Product Ecosystem Integration

Experiment Results fits into Amplitude's analytics ecosystem as a specialized experimentation analysis tool that leverages the platform's core event tracking and user behavior analytics capabilities. It extends Amplitude's product analytics foundation into the experimentation domain, allowing teams to:

- Validate product hypotheses through controlled testing
- Measure feature impact on key business metrics
- Integrate experiment data with broader user journey analytics
- Support data-driven product development workflows

The tool bridges the gap between feature flagging platforms (which control experiment delivery) and analytics platforms (which measure experiment impact), providing a unified analysis layer regardless of the underlying experimentation infrastructure.

## Analysis and Interpretation Features

The platform provides comprehensive statistical analysis through confidence intervals, p-value calculations, and mean-over-time trending analysis. Results are presented through interactive charts that show both cumulative and time-series views of experiment performance, enabling teams to understand both immediate and sustained impact of product changes.

The sequential testing framework allows for early stopping decisions while maintaining statistical rigor, supporting agile experimentation practices where teams need to make rapid decisions based on emerging data patterns.