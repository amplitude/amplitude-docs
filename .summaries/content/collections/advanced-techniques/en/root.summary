## Amplitude Experiment: Advanced Experimentation Platform

Amplitude Experiment is a comprehensive A/B testing and feature flag platform that enables sophisticated experimentation workflows with advanced statistical analysis, traffic management, and evaluation capabilities. The platform supports both local and remote evaluation modes, providing flexibility for different deployment scenarios while maintaining statistical rigor and data integrity.

## Product Architecture and Feature Relationships

The platform operates through several interconnected components that work together to deliver comprehensive experimentation capabilities:

**Evaluation Infrastructure**: The core evaluation system supports both local and remote evaluation modes. Local evaluation flags use Device ID bucketing and run server-side with limited targeting capabilities, while remote evaluation flags support more complex targeting rules and use Amplitude ID bucketing. The system includes proxy support through AWS CloudFront for bypassing domain blocking, with specific cache policies (CachingDisabled, AllViewExceptHostHeader, CORS-with-preflight-and-SecurityHeadersPolicy) and testing via the `/v1/vardata` endpoint.

**Traffic Management System**: A sophisticated traffic allocation system includes mutual exclusion groups that prevent users from being exposed to multiple related experiments simultaneously, and holdout groups that exclude users from experiments to measure long-term cumulative impact. When experiments belong to multiple holdout groups, traffic reduction is multiplicative (e.g., 0.95 * 0.95 = 90.25%).

**Statistical Analysis Engine**: The platform implements advanced statistical methods including Bonferroni correction for multiple hypothesis testing, automatic correction for primary and secondary metrics with multiple treatments, and comprehensive outlier detection using standard deviations, boxplots, and percentiles with mitigation strategies like winsorization and log transforms.

**Dependency Management**: Flag prerequisites create hierarchical dependencies where evaluation of dependent flags requires prerequisite flags to have specific variant values, while circular dependency prevention ensures system stability.

## Key Nomenclature and Definitions

**Bucketing and Assignment**:
- **Sticky Bucketing**: Maintains consistent variant assignments even when targeting criteria or rollout percentages change, available only for feature experiments
- **Bucketing Key**: Identifier used for user assignment (Device ID for local evaluation, Amplitude ID for remote evaluation)
- **Variant Jumping**: Unwanted changes in user variant assignments that sticky bucketing prevents

**Evaluation Modes**:
- **Local Evaluation**: Server-side evaluation with Device ID bucketing and limited targeting capabilities
- **Remote Evaluation**: Client-side evaluation with Amplitude ID bucketing and full targeting rule support

**Traffic Control**:
- **Mutual Exclusion Groups (Mutex)**: Prevent users from being in multiple related experiments simultaneously
- **Holdout Groups**: Exclude percentage of users from experiments to measure cumulative program impact
- **Traffic Allocation**: Percentage-based distribution of users across experiment variants

**Metrics and Analysis**:
- **Sample Ratio Mismatch (SRM)**: Detection system for variant allocation discrepancies
- **Threshold Metrics**: Multi-event conversion measurement using funnel counting
- **Exposure Events**: Events that trigger experiment assignment and measurement

**Advanced Features**:
- **Flag Prerequisites**: Dependencies between flags requiring specific prerequisite variant values
- **URL Redirect Testing**: A/B testing through URL redirects without extensive developer involvement

## Broader Product Ecosystem Integration

Amplitude Experiment integrates deeply with the broader Amplitude ecosystem:

**Analytics Integration**: Seamless data sharing with Amplitude Analytics through JSON import/export of experiment chart settings, shared segmentation capabilities, and unified user property systems. The platform supports advanced metric analysis including funnel analyses where exposure events occur mid-funnel.

**SDK Ecosystem**: Comprehensive SDK support including JavaScript Server SDK (`@amplitude/experiment-node-server`), JavaScript Client SDK (`@amplitude/experiment-js-client`), and server-side rendering implementations that combine both SDKs for optimal performance.

**Data Quality Systems**: Integration with Amplitude's data quality tools including cumulative exposure graphs for monitoring experiment health, sample ratio mismatch detection, and outlier identification systems that work across both Analytics and Experiment products.

**Enterprise Features**: Advanced capabilities available on Enterprise plans including flag prerequisites, comprehensive holdout group analysis, mutual exclusion group management, and enhanced statistical analysis tools.

## API Endpoints and Technical Implementation

**Core Evaluation Endpoints**:
- `/v1/vardata`: Primary endpoint for variant data retrieval and testing
- Server SDK methods: `fetchV2()` for variant fetching per request
- Client SDK initialization with `initialVariants` for SSR implementations

**Configuration APIs**:
- JSON schema support for experiment settings with fields including `variants`, `bucketingGroupType`, `userProperty`, `exposureEvent`, `experimentStartDate`, `experimentEndDate`, and `metrics` arrays
- Flag prerequisite configuration through Dependencies card interface
- Mutual exclusion group and holdout group management APIs

**Analysis and Monitoring**:
- Cumulative exposures graph APIs for monitoring experiment health patterns including increasing/decreasing slopes, divergent lines, and inflection points
- Sample ratio mismatch detection systems
- Statistical significance calculation with multiple hypothesis testing corrections

The platform provides comprehensive debugging tools including cumulative assignment charts, exposure event analysis, and data quality guides for diagnosing issues like variant jumping, instrumentation errors, and authentication pattern problems.