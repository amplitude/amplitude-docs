## Amplitude Experiment Advanced Techniques

Amplitude Experiment is a comprehensive feature flagging and A/B testing platform that enables organizations to run controlled experiments and manage feature rollouts. The advanced techniques documentation covers sophisticated experimentation methodologies, statistical analysis approaches, and complex deployment scenarios for enterprise-scale implementations.

## Product Relationships and Feature Integration

The platform operates through multiple interconnected components that work together to provide a complete experimentation ecosystem:

**Core Evaluation Modes**: The system supports both local and remote evaluation modes. Local evaluation flags use Device ID bucketing and run server-side with limited targeting capabilities, while remote evaluation flags support more complex targeting rules and use Amplitude ID for bucketing. Migration between modes requires careful consideration of bucketing behavior changes and deployment workflows.

**Traffic Management System**: Experiments utilize a sophisticated traffic allocation system involving holdout groups, mutual exclusion groups, and sticky bucketing. Holdout groups exclude user percentages to measure cumulative program impact, while mutual exclusion groups prevent users from exposure to multiple related experiments. These systems interact multiplicatively - users in multiple holdout groups experience compounded traffic reduction (e.g., 0.95 * 0.95 = 90.25% traffic).

**Flag Dependencies and Prerequisites**: Enterprise plans support flag prerequisites, creating dependency chains where evaluation of dependent flags requires prerequisite flags to have specific variant values. This enables complex experiment orchestration and chained testing scenarios while preventing circular dependencies.

**Analytics Integration**: The platform integrates deeply with Amplitude Analytics for metric analysis, outlier detection, and data visualization. Chart settings can be imported/exported as JSON between Experiment and Analytics, maintaining consistency across analysis workflows.

## Key Nomenclature and Definitions

**Sticky Bucketing**: A deterministic hashing algorithm that maintains consistent variant assignments for users even when experiment targeting criteria, percentage rollout, or rollout weights change, preventing variant jumping and ensuring treatment consistency.

**Sample Ratio Mismatch (SRM)**: A data quality issue where actual variant allocation differs from expected traffic allocation, often caused by instrumentation errors, mid-experiment changes, or variant jumping.

**Exposure Events**: Events that indicate when users are actually exposed to experiment variants, distinct from assignment events. Custom exposure events can be configured for specific measurement scenarios.

**Cumulative Exposures Graph**: A visualization showing exposure event accumulation over time, with slope changes indicating exposure rate variations. Increasing slopes show steady growth, decreasing slopes indicate slowing exposure rates, and inflection points reveal traffic allocation or targeting changes.

**Variant Jumping**: When users switch between experiment variants during an experiment, potentially caused by inconsistent bucketing keys, authentication state changes, or sticky bucketing modifications.

**Winsorization**: A statistical technique for handling outliers by capping extreme values at specified percentiles rather than removing them entirely, available for various metric types including totals, sum of property, and average of property metrics.

**Multiple Hypothesis Testing**: Statistical correction applied when testing multiple variants or metrics simultaneously, using Bonferroni correction to control family-wise error rates and prevent inflated false positive rates.

## Broader Product Ecosystem Integration

Amplitude Experiment operates as part of a larger experimentation and analytics ecosystem:

**SDK Integration**: The platform supports multiple SDK implementations including JavaScript Server SDK (`@amplitude/experiment-node-server`) and Client SDK (`@amplitude/experiment-js-client`) for server-side rendering scenarios, enabling seamless variant delivery across different deployment architectures.

**Infrastructure Integration**: Advanced deployment scenarios include AWS CloudFront reverse proxy configuration for bypassing domain blocking, with specific cache policies (CachingDisabled, AllViewExceptHostHeader, CORS-with-preflight-and-SecurityHeadersPolicy) and API endpoint routing (`/v1/vardata`).

**Analytics Platform Connection**: Deep integration with Amplitude Analytics enables sophisticated metric analysis, including funnel analyses with mid-funnel exposure events, threshold metrics using funnel counting, and advanced outlier detection using statistical methods and visualization tools.

**Enterprise Features**: Advanced capabilities like holdout groups, mutual exclusion groups, flag prerequisites, and sticky bucketing are available on Enterprise plans, providing sophisticated experiment orchestration for large-scale programs.

## API Endpoints and Technical Implementation

**Primary API Endpoints**:
- `/v1/vardata` - Core variant data retrieval endpoint used for CloudFront proxy testing and variant fetching
- Evaluation servers: `api.lab.amplitude.com` and `api.lab.eu.amplitude.com` for different regional deployments

**SDK Methods**:
- `ExperimentServer.fetchV2()` - Server-side variant fetching for SSR implementations
- `ExperimentClient.initialVariants` - Client-side initialization with pre-fetched variants

**Configuration APIs**: JSON-based import/export functionality for experiment chart settings, including schema fields like `variants`, `bucketingGroupType`, `userProperty`, `exposureEvent`, and `metrics` arrays.

**Split URL Testing**: Requires Experiment SDK script tag placement in HTML `<head>` section with Analytics SDK for event tracking, supporting low-code visual experimentation scenarios.

The platform emphasizes statistical rigor through automatic multiple hypothesis testing correction, comprehensive outlier detection and mitigation strategies, and sophisticated traffic management systems that enable complex experimental designs while maintaining data quality and statistical validity.