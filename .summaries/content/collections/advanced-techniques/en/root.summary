# Amplitude Experiment: Advanced Techniques

## Product Overview

Amplitude Experiment is a feature experimentation and flag management platform that enables product teams to test hypotheses, roll out features, and measure impact through controlled experiments. The platform supports both local and remote evaluation modes, allowing for client-side and server-side implementations. Key features include variant assignment, traffic allocation, exposure tracking, and statistical analysis of experiment results.

## Key Features and Concepts

### Evaluation Modes
- **Local Evaluation**: Client-side evaluation that processes flag rules directly on the user's device, ideal for performance-critical applications
- **Remote Evaluation**: Server-side evaluation where decisions are made on Amplitude's servers, offering more flexibility for complex targeting rules

### Experiment Types
- **Feature Experiments**: Tests that compare different variants of a feature to measure impact
- **Holdout Groups**: Special experiment groups that exclude users to measure long-term cumulative impacts of features
- **Mutually Exclusive Experiments**: Groups of experiments where users can only participate in one experiment at a time

### Bucketing and Assignment
- **Sticky Bucketing**: Ensures users consistently see the same variant even when targeting criteria change
- **Bucketing Keys**: Identifiers (like device ID or user ID) used to determine variant assignment
- **Traffic Allocation**: Controls what percentage of users are included in experiments

### Analysis Tools
- **Cumulative Exposure Graphs**: Visualize user exposure to experiment variants over time
- **Sample Ratio Mismatch (SRM) Detection**: Identifies when observed variant allocations differ from specified allocations
- **Multiple Hypothesis Testing Correction**: Uses Bonferroni correction to maintain statistical validity when testing multiple variants or metrics

## Product Relationships and Architecture

Amplitude Experiment integrates closely with other Amplitude products:

1. **Amplitude Analytics**: Provides the user data and event tracking infrastructure for measuring experiment results
   - Experiment results can be exported to Analytics for deeper analysis
   - Chart settings can be shared between platforms using JSON import/export

2. **Experiment SDKs**:
   - Client SDKs (JavaScript, iOS, Android) for local evaluation
   - Server SDKs for remote evaluation and server-side rendering
   - Combined implementations for complex use cases like server-side rendering with client-side hydration

3. **Deployment Options**:
   - Direct integration with Amplitude servers
   - Proxy configurations (e.g., AWS CloudFront) for regions with domain restrictions

## Key Nomenclature and Definitions

- **Flag**: A feature toggle that controls access to functionality
- **Experiment**: A controlled test comparing different variants
- **Variant**: A specific version or implementation being tested
- **Exposure Event**: Tracks when a user is exposed to an experiment variant
- **Assignment Event**: Records which variant a user is assigned to
- **Bucketing**: The process of assigning users to variants
- **Holdout Group**: A segment of users excluded from experiments to measure baseline metrics
- **Mutual Exclusion Group**: A collection of experiments where users can only be assigned to one experiment
- **Flag Prerequisites**: Dependencies between flags where one flag's evaluation depends on another flag's result
- **Sample Ratio Mismatch (SRM)**: A statistical anomaly where observed variant allocations differ from expected allocations
- **Variant Jumping**: When users see different variants across sessions, creating inconsistent experiences

## API and Implementation Details

### SDK Initialization

JavaScript Client SDK:
```javascript
import { Experiment } from '@amplitude/experiment-js-client';
const experiment = Experiment.initialize('<API_KEY>', {
  userID: 'user-id'
});
```

JavaScript Server SDK:
```javascript
import { ExperimentServer } from '@amplitude/experiment-node-server';
const experiment = new ExperimentServer({
  apiKey: '<API_KEY>',
  serverUrl: 'https://api.lab.amplitude.com'
});
```

### Variant Fetching

Local Evaluation:
```javascript
const variants = await experiment.fetch();
const variant = variants['flag-key'];
```

Remote Evaluation:
```javascript
const variants = await experiment.fetch({
  user_id: 'user-id',
  device_id: 'device-id'
});
```

Server-Side Rendering:
```javascript
// Server-side
const variants = await experimentServer.fetchV2({
  user_id: userId,
  device_id: deviceId
});

// Client-side hydration
const experimentClient = Experiment.initialize('<API_KEY>', {
  userID: userId,
  initialVariants: variants
});
```

### Advanced Configuration

Flag Prerequisites:
```json
{
  "prerequisites": [
    {
      "flag_key": "prerequisite-flag",
      "variants": ["on", "control"]
    }
  ]
}
```

Mutual Exclusion Groups:
```
Configuration via UI: Add experiments to a mutual exclusion group with defined slots and traffic allocation
```

## Use Cases

1. **Feature Testing**: Compare different implementations to determine which performs better
2. **Gradual Rollouts**: Safely deploy features to increasing percentages of users
3. **Holdout Analysis**: Measure long-term impact by excluding some users from feature exposure
4. **Split URL Testing**: Redirect users to different URLs for marketing tests without developer involvement
5. **Complex Experiment Ecosystems**: Manage multiple related experiments with mutual exclusion groups
6. **Regional Deployments**: Use proxy configurations to ensure global availability

The platform includes advanced analysis capabilities for detecting outliers, interpreting exposure patterns, and maintaining statistical validity across complex experimental designs.