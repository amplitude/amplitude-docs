# Amplitude Experiment: Advanced Techniques

## Product Overview

Amplitude Experiment is a feature experimentation and flag management platform that enables product teams to test hypotheses, roll out features safely, and make data-driven decisions. The platform supports both local and remote evaluation modes, allowing for flexible implementation across client and server environments. Key features include experiment creation, flag management, variant assignment, traffic allocation, and robust analytics integration.

## Key Features and Concepts

1. **Feature Flags and Experiments**
   - **Feature Flags**: Toggle features on/off or control feature rollout
   - **Experiments**: Test different variants of features to measure impact
   - **Evaluation Modes**: Local evaluation (client-side) and remote evaluation (server-side)

2. **User Targeting and Traffic Management**
   - **Targeting Rules**: Define which users see which variants
   - **Traffic Allocation**: Control percentage of users in experiments
   - **Holdout Groups**: Exclude users from experiments to measure long-term impact
   - **Mutual Exclusion Groups**: Prevent users from participating in multiple related experiments

3. **Analytics and Measurement**
   - **Exposure Events**: Track when users are exposed to variants
   - **Metrics**: Measure experiment impact on key performance indicators
   - **Statistical Analysis**: Determine significance of experiment results

4. **Advanced Implementation Techniques**
   - **Sticky Bucketing**: Ensure consistent user experiences
   - **Flag Prerequisites**: Create dependencies between flags
   - **Server-Side Rendering**: Implement experiments in SSR environments
   - **Split URL Testing**: Redirect users to different URLs for testing

## Product Relationships and Architecture

Amplitude Experiment integrates closely with Amplitude Analytics, forming a comprehensive experimentation ecosystem:

1. **Amplitude Analytics Integration**
   - Experiment results are analyzed in Amplitude Analytics
   - Chart settings can be exported/imported between platforms
   - User properties and events from Analytics can be used for targeting

2. **SDK Ecosystem**
   - **Client SDKs**: JavaScript, React, iOS, Android
   - **Server SDKs**: Node.js, Java, Python, Go, Ruby
   - **Evaluation Servers**: Remote evaluation endpoints

3. **Deployment Models**
   - **Local Evaluation**: Fast, client-side evaluation with limited targeting capabilities
   - **Remote Evaluation**: Server-side evaluation with full targeting capabilities
   - **Hybrid Approach**: Server-side rendering with both server and client SDKs

## Key Nomenclature and Definitions

1. **Experiment Terminology**
   - **Flag**: Feature toggle that controls feature visibility
   - **Variant**: A specific version of a feature being tested
   - **Bucketing**: Process of assigning users to variants
   - **Bucketing Key**: Identifier used to determine variant assignment (e.g., deviceID, userID)
   - **Exposure Event**: Analytics event triggered when a user sees a variant
   - **Assignment Event**: Event recording which variant a user was assigned

2. **Analysis Terminology**
   - **Sample Ratio Mismatch (SRM)**: Discrepancy between intended and actual variant allocation
   - **Variant Jumping**: When users see different variants across sessions
   - **Multiple Hypothesis Testing**: Statistical challenge when testing multiple metrics or variants
   - **Bonferroni Correction**: Method to adjust for multiple comparisons
   - **Cumulative Exposures**: Graph showing experiment exposure over time

3. **Advanced Features**
   - **Holdout Groups**: Enterprise feature to exclude users from experiments
   - **Mutual Exclusion Groups**: Enterprise feature to prevent users from being in multiple experiments
   - **Flag Prerequisites**: Enterprise feature creating dependencies between flags

## Implementation Details

### API Endpoints and SDK Usage

1. **Remote Evaluation Endpoint**
   - `https://api.lab.amplitude.com` - Primary evaluation endpoint
   - Can be proxied through AWS CloudFront for regions with domain blocking

2. **JavaScript SDK Initialization**
   ```javascript
   // Client SDK
   const experiment = new Experiment({
     apiKey: 'API_KEY',
     user: {
       user_id: 'user@company.com',
       device_id: 'device_id'
     }
   });
   
   // Server SDK
   const experimentServer = new ExperimentServer({
     apiKey: 'SERVER_API_KEY',
     serverUrl: 'https://api.lab.amplitude.com'
   });
   ```

3. **Variant Fetching**
   ```javascript
   // Client-side
   const variants = await experiment.fetch();
   const variant = experiment.variant('flag-key');
   
   // Server-side
   const variants = await experimentServer.fetchV2({
     user: {
       user_id: 'user@company.com',
       device_id: 'device_id'
     }
   });
   ```

4. **Server-Side Rendering Implementation**
   ```javascript
   // Server-side
   const variants = await experimentServer.fetchV2({user});
   
   // Client-side hydration
   const experiment = new Experiment({
     apiKey: 'API_KEY',
     user: user,
     initialVariants: variants
   });
   ```

5. **Split URL Testing**
   ```html
   <script src="https://cdn.amplitude.com/libs/experiment-js-client/1.0.0/experiment.umd.js"></script>
   <script>
     const experiment = new amplitude.Experiment({
       apiKey: 'API_KEY',
       defaultVariants: {
         'flag-key': 'control'
       }
     });
     experiment.fetch().then(() => {
       const variant = experiment.variant('flag-key');
       if (variant === 'treatment') {
         window.location.href = 'https://treatment-page.com';
       }
     });
   </script>
   ```

### Advanced Analysis Techniques

1. **Outlier Detection and Handling**
   - Standard deviation method: Values > 3 standard deviations from mean
   - Percentile method: Values outside 1st and 99th percentiles
   - Boxplot method: Values outside 1.5 * IQR from quartiles
   - Mitigation: Winsorization, filtering, transformations (log, Box Cox)

2. **Multiple Hypothesis Testing**
   - Bonferroni correction: Divide significance level by number of tests
   - Focus on primary metrics to reduce false positives

3. **Cumulative Exposure Analysis**
   - Interpret slope changes, divergent lines, and inflection points
   - Identify issues with experiment setup and targeting

## Enterprise Features

1. **Holdout Groups**
   - Create via Experiment UI
   - Set percentage of users to exclude from experiments
   - Add experiments to holdout groups
   - Analyze long-term cumulative impact

2. **Mutual Exclusion Groups**
   - Create via Experiment UI
   - Configure slots and traffic allocation
   - Add experiments to mutual exclusion groups
   - Prevents interaction effects between experiments

3. **Flag Prerequisites**
   - Configure dependencies between flags
   - Ensure proper feature hierarchy
   - Use cases: release groups, chained mutual exclusion

Amplitude Experiment provides a comprehensive platform for feature experimentation with robust analytics integration, flexible implementation options, and advanced capabilities for enterprise users.