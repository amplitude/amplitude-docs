## Amplitude Web Experimentation

Amplitude Web Experimentation is a comprehensive A/B testing and experimentation platform that enables teams to run client-side experiments without requiring code changes. The platform centers around a Visual Editor that allows users to create and modify website elements through a point-and-click interface, while also supporting advanced custom code implementations for complex use cases.

## Product Architecture and Feature Relationships

The Web Experimentation platform operates through several interconnected components:

**Core Implementation Layer**: The foundation consists of a dynamically-sized JavaScript script (79KB base + ~1KB per flag) that can be implemented synchronously or asynchronously. The script includes anti-flicker snippets to prevent visual inconsistencies during experiment loading and supports both US (`cdn.amplitude.com`) and EU (`cdn.eu.amplitude.com`) data center endpoints.

**Experiment Configuration**: Web experiments are structured around three primary components that work together:
- **Pages**: Define URL targeting rules and variant scoping using operators like URL Matches Exactly, URL Contains, URL Starts With, and URL Matches Regex
- **Actions**: Specify how variants modify websites through element changes, URL redirects, or custom code injection
- **Targeting**: Control audience segmentation and experiment bucketing through browser and user property evaluation

**Visual Editor Integration**: The Visual Editor serves as the primary interface for creating experiments, allowing users to modify CSS properties, edit HTML content, and configure element selectors without technical expertise. It integrates directly with the Pages functionality for URL preview and targeting configuration.

## Key Nomenclature and Definitions

**Variants**: Different versions of a webpage or experience being tested, each containing specific actions that modify the original page

**Actions**: Modifications applied by variants, including:
- Element changes (display, visibility, text, background, positioning)
- URL redirects with query parameter retention
- Custom code actions (JavaScript, CSS, HTML injection)

**Bucketing**: The process of assigning users to experiment variants based on rollout percentages and distribution settings

**Impression Events**: Tracking events fired when users are exposed to experiments, transformed from `$impression` to `[Experiment] Impression` format with flag_key and variant properties

**Anti-flicker**: A mechanism that prevents visual inconsistencies by hiding page content during experiment evaluation, with a 1-second timeout for remote property resolution

**Page Targeting**: URL-based rules that determine where experiments should run, supporting exact matches, pattern matching, contains operations, and regex expressions

## Broader Product Ecosystem Integration

Web Experimentation integrates extensively with Amplitude's analytics ecosystem and third-party platforms:

**Amplitude Integration**: The platform leverages Amplitude's Browser SDK for user identification and event tracking, utilizing Device ID consistency and Amplitude ID resolution for accurate user assignment. Experiment data flows into Amplitude's analytics for statistical analysis and winner determination.

**Third-Party CDP Integration**: The system supports integration with Customer Data Platforms through:
- Segment integration via query parameters
- Tealium iQ and AudienceStream compatibility
- Custom IntegrationPlugin interface for bespoke integrations
- `experimentIntegration` window variable for custom implementations

**Content Management Systems**: Native plugins are available for WordPress and Shopify, while Google Tag Manager integration is supported through custom HTML tags.

**Tag Manager Implementation**: The platform can be deployed through various tag management systems, with specific support for GTM custom HTML tag implementation.

## Technical Implementation Details

**Performance Characteristics**: The system employs a two-layer caching strategy with CDN and browser caching, using 60-second max-age and stale-while-revalidate policies. Local evaluation occurs synchronously in under 1ms, while remote property evaluation may introduce latency.

**Targeting Evaluation**: The platform distinguishes between:
- Browser properties (local evaluation): Device information, session storage, local storage, document.referrer, UTM parameters
- User properties (remote evaluation): Behavioral cohorts, user enrichment data, IP geolocation

**Utility Functions**: Custom code actions have access to utility functions including:
- `waitForElement()`: For DOM element detection
- `utils.remove()`: For cleanup operations in single-page applications
- MutationObserver integration for dynamic content handling

**API and Configuration**: While specific API endpoints aren't detailed in the documentation, the system supports Management API integration with restrictions on pages functionality for Feature Flags.

**Post-Experiment Workflow**: The platform includes comprehensive post-experiment processes for winner analysis, production code migration, and experiment deactivation to reduce technical debt and optimize performance.

The billing model is based on monthly impression volume, calculated using the formula M * E * P (Monthly Tracked Users × Experiments × Participation rate), making cost management predictable for organizations running multiple concurrent experiments.