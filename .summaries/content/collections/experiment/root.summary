Amplitude Experiment is a comprehensive behavioral experimentation and feature flag platform that enables teams to run A/B tests and manage progressive feature delivery through a workflow-driven approach. The platform supports both statistical experimentation with hypothesis testing and feature flagging for controlled rollouts without metrics tracking.

## Core Product Architecture

The platform operates on a hierarchical data model consisting of organizations, projects, deployments, flags/experiments, variants, and users. Deployments serve as the primary configuration layer, available in client-side and server-side types, each with unique deployment keys for SDK authentication. The system supports two primary evaluation modes: remote evaluation for advanced targeting capabilities and local evaluation for sub-millisecond performance.

Remote evaluation leverages Amplitude's evaluation servers to provide sophisticated targeting features including Amplitude ID resolution, IP geolocation, property canonicalization, cohort membership targeting, and user enrichment using historical analytics data. Local evaluation runs the evaluation logic directly within SDKs, achieving sub-millisecond performance but with limited targeting capabilities compared to remote evaluation.

## Key Features and Capabilities

The platform distinguishes between feature flags and experiments, where experiments include statistical analysis and hypothesis testing while feature flags focus purely on progressive feature delivery. Experiments support multiple statistical models including sequential testing and T-test analysis, with comprehensive metrics tracking through primary success metrics, secondary metrics, and guardrail metrics.

Variant management utilizes a sophisticated bucketing system with consistent hashing using murmur3 algorithms, bucketing salt for randomization, and allocation percentages for traffic distribution. The evaluation process includes pre-targeting steps such as flag dependencies, mutual exclusion groups, holdout groups, sticky bucketing, and individual inclusions before final variant assignment.

## Targeting and Segmentation

Amplitude Experiment provides extensive targeting capabilities through user segments, cohort targeting, and dimensional analysis. Cohort targeting supports both static and dynamic user cohorts with hourly synchronization to either the Amplitude Experiment destination (remote evaluation) or Experiment Local Evaluation destination (local evaluation, server-side SDKs only). The platform includes dimensional analysis features for filtering QA users and internal traffic from experiment results.

## Analysis and Monitoring

The Analysis view provides comprehensive statistical measurements including relative performance lift calculations, confidence intervals, statistical significance p-values, and absolute value conversions. The platform supports CUPED variance reduction, Bonferroni correction for multiple comparisons, and sample ratio mismatch (SRM) detection to ensure experiment validity.

Notification systems integrate with Slack channels and webhooks for real-time alerts on flag lifecycle events, experiment status changes, and statistical anomalies. Alert scoping can be configured by project, deployment, or tags with webhook schema validation using signing keys.

## SDK Integration and Implementation

The platform provides multi-platform SDK support including TypeScript/JavaScript, Kotlin, Objective-C, Swift, and Python with comprehensive configuration options. SDKs support automatic exposure tracking, session management, and event tracking through the BaseEvent class. Server-side SDKs offer additional capabilities for cohort targeting and local evaluation.

Key API endpoints include the Analytics REST API v2.0 for exposure tracking and the Management API for programmatic experiment management. SDK configuration utilizes cohortSyncConfig for cohort synchronization with API keys, secret keys, and deployment keys for authentication.

## Access Control and Permissions

The platform implements project-level permissions that operate independently from Analytics permissions, featuring role-based access control with Viewer, Member, Manager, and Admin roles. Flag-level access controls provide granular restrictions on experiment editing capabilities, with Enterprise customers having access to Management API bypass functionality.

## Key Nomenclature

- **Bucketing Units**: User identifiers (user_id, device_id, or custom group properties with Accounts add-on)
- **Allocation**: Traffic percentage assigned to experiments
- **Payload Variables**: JSON configuration data passed with variants
- **Exposure Events**: Tracking events when users see experiment variants
- **Assignment Events**: Server-side tracking of variant assignments
- **Enrollment Events**: Initial user entry into experiments
- **SUTVA**: Stable Unit Treatment Value Assumption for experiment validity
- **MDE**: Minimum Detectable Effect for statistical power calculations
- **Variant Jumping**: Undesired changes in user variant assignments

The platform integrates seamlessly with the broader Amplitude ecosystem, leveraging Analytics project structures, user cohorts, and historical behavioral data to enhance targeting precision and experimental insights.