Amplitude Experiment is a comprehensive behavioral experimentation and feature flag platform that enables teams to run A/B tests and manage feature rollouts through a workflow-driven approach. The platform supports both statistical experimentation with hypothesis testing and feature flag management for progressive delivery, operating as a dual-purpose system for controlled feature releases and data-driven experimentation.

## Core Architecture and Evaluation Framework

The platform operates through two distinct evaluation modes that balance performance with functionality. **Remote Evaluation** fetches variants from Amplitude's evaluation servers, providing advanced targeting capabilities including Amplitude ID resolution, IP geolocation, property canonicalization, cohort membership targeting, user enrichment using historical analytics data, and sticky bucketing. **Local Evaluation** runs evaluation logic directly in the SDK for sub-millisecond performance through consistent bucketing and targeting segments, though with limitations including lack of Amplitude ID resolution, user enrichment, and sticky bucketing capabilities.

## Product Hierarchy and Data Model

The platform follows a structured organizational hierarchy: Organizations contain Projects, which contain Deployments (client-side or server-side with deployment keys), which contain Flags/Experiments with variants. Users are identified through user_id/device_id requirements, with group support available through the Accounts add-on. Variants contain both value and payload properties with kebab-case formatting requirements, enabling complex configuration delivery through JSON payloads.

## Key Nomenclature and Definitions

**Flags/Experiments**: The core entities that control feature visibility and experimentation logic
**Variants**: Different versions or configurations within a flag, containing value and payload properties
**Deployment Keys (DEPLOYMENT_KEY)**: Authentication tokens for SDK access to specific deployments
**Sticky Bucketing**: Ensures users remain in the same variant across sessions
**Consistent Bucketing**: Uses murmur3 hashing algorithm with bucketing salts for reliable variant assignment
**Mutual Exclusion Groups**: Prevent users from being exposed to multiple conflicting experiments
**Holdout Groups**: Control groups that receive no treatment for baseline comparison
**Sample Ratio Mismatch (SRM)**: Statistical anomaly indicating potential bucketing issues
**CUPED**: Variance reduction technique for improved statistical power
**Minimum Detectable Effect (MDE)**: Smallest effect size the experiment can reliably detect

## Experimentation and Statistical Framework

The platform implements a comprehensive A/B testing workflow encompassing hypothesis formation, metric selection (primary success metrics, secondary metrics, and guardrail metrics), treatment variant creation, and statistical analysis. The default statistical model uses sequential testing with T-test options available. Key statistical features include CUPED variance reduction, Bonferroni correction for multiple comparisons, and confidence interval calculations. The Analysis view provides detailed statistical evaluation through relative performance metrics, significance testing, and absolute values comparison.

## Targeting and Segmentation Capabilities

Sophisticated targeting is achieved through static and dynamic cohorts that sync hourly to remote and local evaluation destinations. The system supports individual inclusions, user ID targeting, device ID targeting, and cohort targeting for granular experiment exposure control. CohortSyncConfig enables local evaluation cohort targeting, while the "Exclude testers" functionality in Targeting settings filters QA users and internal traffic through Dimensional Analysis.

## Integration Architecture and SDK Ecosystem

Multi-platform SDK support includes TypeScript, Kotlin, Objective-C, Swift, and Python implementations with consistent initialization patterns. SDKs support defaultTracking configuration, session management, and automatic exposure tracking. The platform integrates with multiple API layers including the Evaluation REST API for variant fetching, Analytics REST API v2.0 for exposure tracking, and Management API for programmatic flag management.

## Access Control and Permissions Model

Amplitude Experiment implements project-level permissions operating independently from Analytics permissions through a role-based system including Viewer, Member, Manager, and Admin roles. Enterprise customers receive enhanced security through flag-level access restrictions and restricted flag editors, while the Management API provides bypass capabilities for programmatic access.

## Key API Endpoints and Technical Integration Points

- **Evaluation REST API**: Primary endpoint for variant fetching and evaluation
- **Analytics REST API v2.0**: Handles exposure tracking and event data
- **Management API**: Enables programmatic flag lifecycle management
- **CohortSyncConfig**: Configures cohort targeting for local evaluation
- **Project API Keys**: Authenticate evaluation access across deployments

## Monitoring and Notification Infrastructure

The platform provides comprehensive monitoring through Slack channel integration and webhook configurations with signing key verification. Alerts can be scoped by project, deployment, or tags for flag lifecycle events (created/updated/deleted) and sample-ratio mismatch detection, ensuring teams maintain visibility into experiment health and feature rollout status.

## Broader Product Ecosystem Integration

Amplitude Experiment operates as a core component within the broader Amplitude analytics ecosystem, leveraging historical user data for enrichment and targeting while feeding experimentation results back into the analytics pipeline. The platform's integration with Amplitude Analytics enables sophisticated user segmentation based on behavioral data, creating a unified experimentation and analytics workflow. The system supports both standalone feature flag management for progressive delivery and full statistical experimentation, positioning it as a comprehensive solution for data-driven product development and controlled feature releases.