Amplitude Experiment is a behavioral experimentation and feature flag platform that enables organizations to conduct A/B tests and manage progressive feature delivery through a comprehensive workflow-driven approach. The platform serves dual purposes: statistical experimentation with hypothesis testing for data-driven decision making, and feature flagging for controlled rollouts without metrics tracking requirements.

## Core Architecture and Evaluation Models

The platform operates on two distinct evaluation paradigms optimized for different use cases:

**Remote Evaluation** utilizes Amplitude's cloud-based evaluation servers to fetch variants, providing advanced targeting capabilities including Amplitude ID resolution, IP geolocation, property canonicalization, cohort membership targeting, and user enrichment using historical analytics data. This approach maximizes targeting sophistication but requires network requests for each evaluation.

**Local Evaluation** executes evaluation logic directly within client SDKs, delivering sub-millisecond performance through consistent bucketing algorithms. However, this approach has limited targeting capabilities, excluding Amplitude ID resolution, user enrichment, and sticky bucketing functionality in favor of speed and reduced network dependency.

## Data Model and Hierarchical Structure

The system follows a clear organizational hierarchy: Organizations contain Projects, which house Deployments (differentiated as client-side or server-side with unique deployment keys), Flags/Experiments (supporting both local and remote evaluation modes), Variants (containing value/payload properties), and Users (requiring user_id or device_id with optional group support via the Accounts add-on).

This hierarchical structure enables granular access control and resource organization while maintaining clear separation of concerns between different experimental contexts and deployment environments.

## Experimentation Implementation and Statistical Framework

The evaluation process follows a systematic pre-targeting workflow that includes activation checks, flag dependencies, individual inclusions, and sticky bucketing, followed by targeting segments and consistent bucketing using murmur3 hashing with bucketing salt and allocation percentages. This methodology ensures reliable variant assignment while preventing sample ratio mismatch (SRM) and variant jumping.

The platform supports two statistical analysis models: Sequential Testing for continuous monitoring and hypothesis evaluation, and T-test for traditional fixed-horizon analysis. Experiments operate under SUTVA (Stable Unit Treatment Value Assumption) with configurable bucketing units including user, organization, or custom company_id through the Accounts add-on.

## Key Platform Capabilities

**Cohort Targeting** enables sophisticated audience segmentation using both static and dynamic cohorts that synchronize hourly to remote and local evaluation destinations. Local evaluation scenarios require SDK configuration with API and secret keys for cohort access.

**Dimensional Analysis** provides quality assurance filtering capabilities, allowing teams to exclude internal traffic and test users from experiment analysis through targeting settings and user segment controls, ensuring clean experimental data.

**Exposure Tracking** captures user interactions with feature flag variants through the Analytics REST API v2.0 and client-side SDKs with automatic exposure tracking functionality, feeding comprehensive data into analysis views for statistical evaluation.

## Analysis and Monitoring Infrastructure

The Analysis View presents comprehensive statistical measurements including relative performance lift calculations, confidence intervals, significance testing with p-values, and absolute conversion percentages. The system distinguishes between recommendation metrics (primary success criteria) and secondary metrics for holistic experiment evaluation.

**Notifications** support Slack channel integration and webhook configurations with signing key verification, enabling real-time alerts for flag lifecycle events (created/updated/deleted) and sample-ratio mismatch detection. Notification scoping can be configured across projects, deployments, or tag-based filtering.

## Access Control and Security Framework

Project-level permissions operate independently from Analytics permissions, featuring role-based access control with four tiers: Viewer, Member, Manager, and Admin. Flag-level access controls provide granular restrictions for experiment editing capabilities. Enterprise customers can leverage Management API bypass capabilities for advanced permission management scenarios.

## API Integration and SDK Ecosystem

The platform provides comprehensive SDK support across multiple platforms including TypeScript/JavaScript, Kotlin, Objective-C, Swift, and Python, with standardized initialization patterns and configuration options for session management. Event tracking utilizes BaseEvent classes for consistent data structure across implementations.

Key API endpoints include:
- **Analytics REST API v2.0** for exposure tracking and event submission
- **Management API** for experiment configuration and administrative operations
- **Evaluation REST API** for programmatic access to experiment configurations and variant assignments

Command-line integration supports curl requests for exposure event submission, enabling server-side tracking implementations.

## Technical Implementation and Performance Optimization

The system employs kebab-case variant formatting conventions and supports JSON payloads for complex variant configurations. Cohort propagation operates on hourly sync intervals, while consistent bucketing utilizes murmur3 hashing algorithms for deterministic variant assignment.

Edge evaluation capabilities are available for Node.js environments with optimized cold start performance characteristics, enabling low-latency feature flag evaluation in serverless and edge computing contexts.

## Product Ecosystem Integration

Amplitude Experiment integrates deeply with the broader Amplitude Analytics ecosystem, leveraging historical user data for enriched targeting and providing seamless data flow between experimentation and analytics platforms. The Accounts add-on extends functionality for B2B use cases with organization-level bucketing and analysis capabilities.

The platform's dual evaluation model and comprehensive API ecosystem position it as both a standalone experimentation platform and an integrated component within larger product development and analytics workflows, supporting everything from simple feature toggles to complex multivariate experiments with sophisticated statistical analysis requirements.