Amplitude Experiment is a comprehensive behavioral experimentation platform that enables organizations to conduct A/B tests and deploy feature flags through a workflow-driven approach. The platform supports both hypothesis-driven experimentation and progressive feature delivery, utilizing sequential testing as the default statistical model over traditional T-tests for improved accuracy and reduced false positives.

## Product Architecture and Feature Relationships

The platform operates on a hierarchical data model structure consisting of organizations, projects, deployments, flags/experiments, variants, and users. Deployments serve as the core organizational unit, available in both client-side and server-side configurations, each utilizing unique deployment keys for SDK authentication and configuration.

Amplitude Experiment offers two primary evaluation modes that determine how variant assignments are calculated:

**Remote Evaluation** leverages Amplitude's evaluation servers to fetch variants with comprehensive user enrichment capabilities. This includes Amplitude ID resolution, IP geolocation targeting, property canonicalization, cohort membership targeting, and access to user properties from historical analytics data. Remote evaluation supports sticky bucketing and behavioral cohorts with hourly synchronization.

**Local Evaluation** runs evaluation logic directly within SDKs, achieving sub-millisecond performance by eliminating network requests. However, this approach has limitations including no Amplitude ID resolution, restricted user enrichment, and unavailable sticky bucketing capabilities.

The platform's targeting system supports multiple audience segmentation approaches including cohort targeting (both static and dynamic), individual user inclusions, and complex targeting segments. Cohort targeting operates differently between evaluation modes - remote evaluation syncs hourly to the Amplitude Experiment destination, while local evaluation requires server-side SDKs and syncs to the Experiment Local Evaluation destination.

## Key Nomenclature and Definitions

**Bucketing** refers to the consistent algorithm that determines user variant assignment using murmur3 hashing. The system supports various bucketing units including user_id, device_id, and organization-level identifiers (available with Accounts add-on).

**Variants** represent different treatment conditions within experiments, each containing value and payload properties. Payloads enable complex configuration through JSON objects, allowing dynamic feature behavior modification.

**Allocation** determines the percentage of users exposed to an experiment, while variant distribution weights control how users are split between different treatment conditions.

**Exposure Events** track when users encounter feature flag variants, automatically captured by client-side SDKs or manually tracked via the Analytics REST API v2.0.

**CUPED (Controlled-experiment Using Pre-Experiment Data)** provides variance reduction techniques to improve statistical power and reduce required sample sizes.

**Guardrail Metrics** monitor for negative impacts during experiments, while primary and secondary success metrics measure intended outcomes.

## Statistical Analysis and Measurement

The Analysis view provides comprehensive statistical evaluation including relative performance calculations, confidence intervals, significance testing, and absolute value measurements. The platform supports sequential testing methodology, allowing for continuous monitoring and early stopping decisions while maintaining statistical rigor.

Dimensional Analysis enables filtering of QA users and internal traffic through the "Exclude testers" functionality, ensuring clean experiment results by removing non-representative user segments.

## API Endpoints and Implementation

The platform provides multiple integration methods:

- **Experiment SDKs** available across TypeScript, Kotlin, Objective-C, Swift, and Python with consistent initialization patterns
- **Analytics REST API v2.0** for exposure tracking and event ingestion
- **Management API** for programmatic experiment and permission management
- **Edge Evaluation** for Node.js server-side implementations

SDK configuration supports various tracking options including defaultTracking settings, session management parameters (minTimeBetweenSessionsMillis), and automatic event property capture.

## Permission and Access Control

The platform implements project-level permissions that operate independently from Analytics permissions. The role-based system includes Viewer, Member, Manager, and Admin roles with granular controls over experiment creation, modification, and activation. Enterprise customers receive additional flag-level access restrictions and enhanced permission management capabilities.

## Broader Ecosystem Integration

Amplitude Experiment integrates deeply with the Amplitude Analytics platform, leveraging user behavioral data for enhanced targeting and analysis. The system supports mutual exclusion groups to prevent experiment interference, holdout groups for long-term impact measurement, and seamless conversion between feature flags and full experiments as requirements evolve.

The platform's consistent bucketing algorithm ensures stable user experiences across experiment lifecycle changes, while the comprehensive data model enables sophisticated audience targeting and statistical analysis workflows.