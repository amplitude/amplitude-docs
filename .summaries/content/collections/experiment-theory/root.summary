# Amplitude Experiment: Experimentation Platform

## Product Overview

Amplitude Experiment is a statistical experimentation platform for designing, running, and analyzing A/B tests and Multi-Armed Bandit experiments to measure product change impacts. It provides statistical tools for determining experiment parameters, analyzing results, and making data-driven decisions based on empirical evidence.

## Key Features and Concepts

### Experiment Types
- **A/B Testing**: Traditional hypothesis testing comparing a control group against one or more variants
- **Multi-Armed Bandit**: Adaptive experimentation that automatically allocates more traffic to better-performing variants

### Statistical Analysis Tools
- **Welch's T-test**: Statistical method for comparing means between two populations
- **Minimum Detectable Effect (MDE)**: The smallest effect size an experiment is designed to detect

### Experiment Design Components
- **Sample Size Requirements**: Calculations to determine necessary users per variant
- **Duration Estimator**: Tool to predict experiment runtime
- **Exposure Tracking**: Monitoring of cumulative exposure throughout the experiment

## Key Nomenclature and Definitions

### Statistical Terms
- **Minimum Detectable Effect (MDE)**: Smallest meaningful change in a metric that an experiment should detect, expressed as a percentage change from control mean
- **Statistical Significance**: Likelihood that an observed effect is not due to random chance
- **Two-sided Test**: Tests for differences between variants in either direction
- **One-sided Test**: Tests for differences in only one direction
- **Central Limit Theorem**: Statistical principle allowing normal distribution assumptions with large enough sample sizes

### Experiment Metrics
- **Success Metrics**: Primary metrics determining experiment success
- **Guardrail Metrics**: Secondary metrics monitored to ensure changes don't negatively impact important product aspects
- **Control Mean**: Baseline metric value observed in the control group
- **Conversion Rate**: Percentage of users completing a desired action

### Experiment Monitoring
- **Samples Per Variant Needed**: Required users in each variant for statistical validity
- **Cumulative Exposure Graph**: Visual representation of user exposure over time
- **Sample Size Target**: Total users required across all variants
- **Exposure Remaining**: Additional user exposure needed for statistical validity

## Feature Relationships

The platform integrates several components working together throughout the experimentation process:

1. **Experiment Design**:
   - MDE settings directly impact required sample size (smaller MDE requires larger sample size)
   - Experiment type (A/B vs Multi-Armed Bandit) affects how MDE is applied

2. **Experiment Monitoring**:
   - Duration estimator uses MDE and current traffic to predict completion
   - Cumulative exposure graphs track progress toward required sample size

3. **Analysis**:
   - Welch's T-test analyzes results once sample size requirements are met
   - Statistical significance is determined based on pre-defined MDE and test parameters

## Product Ecosystem Integration

Amplitude Experiment appears to be part of a broader Amplitude analytics ecosystem, leveraging user data and metrics from the core analytics product. Experiment results can likely be analyzed within the context of other Amplitude features, creating a comprehensive data-driven decision framework.

## Best Practices

1. **Avoid Peeking**: Do not analyze results before reaching required sample size to prevent false positives
2. **Ensure Adequate Samples**: Typically 355+ samples per variant to ensure Central Limit Theorem applies
3. **Consider MDE Tradeoffs**: Balance between experiment duration and sensitivity when setting MDE values