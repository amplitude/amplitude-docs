## Amplitude Destination Catalog

Amplitude's destination catalog represents a comprehensive ecosystem of data integration endpoints that enable organizations to activate their behavioral analytics data across marketing, customer engagement, experimentation, and business intelligence platforms. The catalog encompasses over 100 destination integrations spanning multiple categories and integration patterns.

### Core Integration Architecture

The destination catalog operates through three primary integration patterns:

**Event Streaming Destinations** forward real-time user events and properties from Amplitude to external platforms using APIs like HTTP V2 and Identify API. These integrations typically require authentication tokens, support event filtering, and maintain user property synchronization with configurable delivery mechanisms.

**Cohort Sync Destinations** export behavioral user segments from Amplitude to marketing and engagement platforms for audience targeting. These integrations support various sync cadences (real-time, hourly, daily, scheduled) and require user identifier mapping between platforms (email, user_id, device IDs, custom identifiers).

**Raw Data Export Destinations** provide bulk data transfer capabilities to data warehouses and storage platforms, supporting historical backfills, recurring syncs, and structured data schemas with deduplication and integrity checking mechanisms.

### Platform Categories and Use Cases

**Marketing Automation & Customer Engagement** platforms (Braze, Customer.io, Klaviyo, Mailchimp, HubSpot, Salesforce Marketing Cloud) enable personalized messaging campaigns based on behavioral cohorts and real-time event triggers. These integrations typically require API key authentication and support email/SMS/push notification targeting.

**Advertising & Attribution Networks** (Facebook Ads, Google Ads, TikTok Ads, LinkedIn Ads, Snapchat Ads) facilitate audience creation for retargeting campaigns using device identifiers (IDFA, GAID), email addresses, and phone numbers with SHA256 encryption requirements.

**Experimentation & Feature Management** platforms (Optimizely, LaunchDarkly, Split, Statsig) leverage behavioral cohorts for experiment targeting and feature flag segmentation, enabling data-driven product development workflows.

**Data Infrastructure & Warehousing** destinations (Snowflake, Google BigQuery, Amazon S3, Amazon Redshift) support enterprise data architecture with structured schemas, partitioning strategies, and integration with business intelligence tools.

**Customer Success & Product Analytics** platforms (Planhat, Productboard, Amplitude's own ecosystem) enable customer health scoring, feedback analysis, and product roadmap prioritization using behavioral data.

### Key Technical Specifications

**Authentication Mechanisms** vary by platform but commonly include API keys, OAuth tokens, service account credentials, and webhook authentication. Many integrations require specific permission scopes and role-based access controls.

**User Identifier Mapping** represents a critical configuration requirement, supporting various identifier types including user_id, email addresses, device identifiers (IDFA, GAID, Android ID), platform-specific IDs, and custom external identifiers with deduplication logic.

**Data Transformation & Filtering** capabilities enable selective event forwarding, property mapping, and payload customization using templating engines like Apache FreeMarker for webhook destinations.

**Rate Limiting & Error Handling** implementations include exponential backoff retry mechanisms, 429 throttling responses, request size limits (commonly 2MB), and delivery confirmation systems.

### Integration Patterns and Nomenclature

**Cohort Sync Cadences** support multiple scheduling options including real-time streaming, hourly updates, daily synchronization, and custom scheduled intervals with batch processing capabilities.

**Event Streaming Configurations** enable selective event forwarding through "Send Events" filters, property selection mechanisms, and user forwarding toggles with anonymous user handling policies.

**Payload Structures** follow standardized formats including cohort membership updates with `in_cohort` boolean flags, `computed_time` timestamps, `message_id` deduplication keys, and user property arrays.

**Schema Definitions** for data warehouse destinations include structured tables with `amplitude_id` primary keys, `event_properties` JSON/SUPER columns, `user_properties` dictionaries, and temporal partitioning by `server_upload_time`.

### Ecosystem Integration Points

The destination catalog integrates deeply with Amplitude's broader product ecosystem including **Amplitude Data** for raw event exports, **Amplitude Activation** for real-time streaming, and **Behavioral Cohorts** for audience segmentation. Portfolio projects enable cross-application data sharing, while organization-level configurations support enterprise deployment patterns.

**API Endpoints** commonly referenced include platform-specific ingestion URLs, authentication endpoints for token generation, and webhook callback mechanisms for bidirectional data flow. Many integrations support both production and sandbox environments with separate credential management.

The catalog represents a mature data activation platform enabling organizations to operationalize behavioral analytics across their entire technology stack, from real-time personalization to long-term strategic analysis through comprehensive data warehouse integration patterns.