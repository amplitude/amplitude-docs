## Amplitude Destination Catalog

Amplitude's destination catalog is a comprehensive data activation platform featuring over 100 integrations that enable businesses to operationalize behavioral analytics data across their technology stack. The catalog serves as Amplitude's primary customer data platform capability, transforming analytics insights into actionable customer experiences through real-time data distribution to marketing, product, and engagement platforms.

## Core Product Architecture

The destination catalog operates on four primary integration patterns that define how Amplitude data flows to external systems:

**Event Streaming Destinations** provide real-time forwarding of user behavioral events and properties through HTTP APIs. These integrations support granular event filtering, custom property mapping, and immediate data transmission for time-sensitive use cases like personalization and fraud detection.

**Cohort Syncing Destinations** export user segments built within Amplitude's analytics platform to downstream tools for audience targeting and campaign activation. Cohorts synchronize on configurable cadences (real-time, hourly, daily, scheduled) and support multiple user identifier mapping strategies including email, user_id, device IDs, and custom properties.

**Warehouse Destinations** facilitate bulk export of raw event data and merged user profiles to cloud data warehouses (Snowflake, BigQuery, Redshift) for advanced analytics, data science workflows, and enterprise reporting requirements.

**Raw Events Integrations** provide direct access to Amplitude's event stream for custom ETL processes, data lake architectures, and proprietary analytics pipelines.

## Product Ecosystem Integration

The destination catalog integrations span six primary functional categories that represent the modern customer experience technology stack:

**Marketing Automation & CRM Platforms** (HubSpot, Salesforce Marketing Cloud, Braze, Iterable, Customer.io) receive Amplitude cohorts and behavioral events to power personalized campaigns, lead scoring models, and automated customer journey orchestration.

**Paid Media & Ad Networks** (Facebook Ads, Google Ads, TikTok Ads, LinkedIn Ads, Snapchat) leverage Amplitude's behavioral segments for lookalike audience creation, conversion tracking, and performance marketing optimization.

**Product Experience Platforms** (Appcues, CommandBar, Userflow, Chameleon) consume Amplitude cohorts to trigger contextual in-app experiences, onboarding flows, and feature adoption campaigns based on user behavior patterns.

**Customer Success & Support Tools** (Planhat, Intercom, Zendesk) utilize Amplitude data for proactive customer health monitoring, support ticket prioritization, and retention risk identification.

**Experimentation & Feature Management** (Optimizely, LaunchDarkly, Split, Statsig) integrate with Amplitude for behavior-based experiment targeting, feature flag management, and statistical analysis of product changes.

**Business Intelligence & Analytics** platforms receive structured data exports for custom reporting, executive dashboards, and cross-platform attribution analysis.

## Key Nomenclature and Definitions

**Cohorts** represent user segments built in Amplitude based on behavioral criteria, demographic properties, or computed user states. Cohorts serve as the primary mechanism for audience activation across marketing and product platforms.

**Event Streaming** refers to real-time forwarding of individual user actions and property updates from Amplitude to destination platforms, enabling immediate response to user behavior.

**User Identifier Mapping** defines how Amplitude user records are matched to user profiles in destination systems, supporting email addresses, platform-specific IDs, device identifiers (IDFA, GAID, Android ID), and custom user properties.

**Sync Cadences** specify the frequency of data transmission between Amplitude and destinations, ranging from real-time streaming to scheduled batch updates based on use case requirements and platform capabilities.

**Destination Ownership** distinguishes between Amplitude-maintained integrations (supported directly by Amplitude) and partner-maintained integrations (supported by the destination platform vendor).

## Technical Implementation Patterns

### Authentication Methods

The catalog implements three primary authentication patterns:

**API Key Authentication** utilizes platform-specific API keys, tokens, or credentials for secure data transmission, representing the most common authentication method across integrations.

**OAuth Authentication** provides secure, token-based access for platforms like Google, Facebook, HubSpot, and Salesforce, with proper permission scoping and refresh token management.

**Service Account Authentication** employs IAM roles and service principals for cloud platforms (AWS, Google Cloud, Azure), enabling secure data export with granular permission controls.

### Data Formats and Schemas

**JSON Format** serves as the standard for event streaming, utilizing Amplitude's Export API schema with structured fields including `user_id`, `event_name`, `event_properties`, `user_properties`, and timestamp data.

**CSV Format** supports cohort exports with tabular data including user identifiers and optional user properties for platforms requiring structured file imports.

**Warehouse Schemas** implement structured table formats with platform-specific column types (VARCHAR, SUPER, VARIANT) for event tables and merged user profile tables.

### Performance and Rate Limiting

The catalog implements comprehensive performance controls:

**Rate Limiting** varies by destination with common constraints including 2MB request size limits, daily API call quotas (e.g., 24 calls/day for TikTok Ads), and user throughput limits (e.g., 1000 users/minute for Talon.One).

**Retry Mechanisms** handle temporary failures through exponential backoff with jitter, typically implementing 9 retry attempts over 4 hours for webhook destinations.

**Sync Performance** optimization includes batching strategies, parallel processing, and incremental updates based on `server_upload_time` partitioning for warehouse destinations.

## API Endpoints and Technical Interfaces

### Cohort Synchronization APIs

Standard cohort sync implementations utilize:
- `POST /cohorts/{cohort_id}/users` for adding users to destination cohorts
- `DELETE /cohorts/{cohort_id}/users` for removing users from destination cohorts  
- `GET /cohorts/{cohort_id}/status` for monitoring sync status and performance metrics

### Event Streaming APIs

Real-time event forwarding commonly implements:
- `POST /events` for individual event transmission
- `POST /identify` for user property updates and profile enrichment
- `POST /batch` for bulk event transmission and improved throughput

### Warehouse Export Operations

Data warehouse integrations provide:
- Recurring sync jobs with configurable frequencies (hourly, daily, weekly)
- Manual backfill capabilities for historical data export
- Incremental update mechanisms for efficient data synchronization
- Schema evolution support for changing event and property structures

## Broader Product Ecosystem Context

The destination catalog represents Amplitude's evolution from a behavioral analytics platform to a comprehensive customer data platform (CDP). By enabling data activation across the entire customer experience technology stack, the catalog positions Amplitude as the central nervous system for customer data orchestration.

The catalog's integration breadth spans the complete customer lifecycle from acquisition (paid media platforms) through activation (product experience tools) to retention (customer success platforms), enabling businesses to create cohesive, data-driven customer experiences across all touchpoints.

Integration maintenance follows a hybrid model with both Amplitude-maintained and partner-maintained destinations, ensuring comprehensive platform coverage while distributing support responsibilities across the ecosystem. This approach enables rapid expansion of integration capabilities while maintaining quality and reliability standards for core use cases.