## Summary
This documentation page explains how to backfill historical data into Amplitude using the Batch Event Upload API, covering considerations, limits, best practices, and the impact on user properties. It details how to handle large data volumes, avoid overwriting current user properties with `$skip_user_properties_sync`, and manage throttling limits of 500K events per device ID daily.

## Keywords
- Batch Event Upload API
- data backfill
- historical data import
- user property sync
- insert_id deduplication
- throttling limits
- backfill best practices
- skip_user_properties_sync
- ingestion workers
- daily quota limits