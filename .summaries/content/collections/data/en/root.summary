Amplitude Data is a comprehensive data governance and management platform that provides tools for planning, implementing, and maintaining analytics instrumentation across the entire data lifecycle. The platform serves as a centralized data catalog that enables organizations to create structured tracking plans, generate type-safe code, and ensure data quality through real-time monitoring and validation.

## Core Platform Architecture

Amplitude Data operates as the governance layer for Amplitude's analytics ecosystem, integrating with multiple data ingestion methods including client-side SDKs (Browser, Android, iOS, React Native, Unity, Flutter), server-side SDKs (Node.js, Go, Python, Java), and third-party integrations. The platform supports both real-time event streaming through the HTTP V2 API and batch processing via the Batch Event Upload API, with specific endpoints for different use cases including the Evaluation API for experimentation features.

The system employs a Git-like branching model for tracking plan management, allowing teams to create feature branches, implement changes through merge requests with team reviews, and publish versioned tracking plans. This workflow integrates with the Ampli CLI tool, which generates type-safe wrapper code for SDKs based on tracking plan definitions, providing compile-time validation and autocompletion for developers.

## Data Ingestion and Processing

Amplitude Data handles multiple data ingestion pathways with specific technical requirements and limitations. The platform processes IP addresses through MaxMind GeoIP lookup for location properties (location_lat, location_long), automatically parses user agent strings for device information (device_brand, device_manufacturer, device_model, os_name, os_version), and supports custom location values through the HTTP V2 API. Bot traffic filtering utilizes the IAB/ABC International Spiders and Bots List for User-Agent detection across legacy JavaScript SDK, TypeScript Browser SDK (v1.10.0+), and HTTP/Batch API implementations.

For high-volume data scenarios, the platform supports data backfill through the Batch Event Upload API with specific ingestion limits: 500K events per device ID daily, 100 batches per second, and 1000 events per second. The system includes throttling mechanisms (429 response codes) and supports the `$skip_user_properties_sync` flag for maintaining data integrity during historical imports.

## Schema Management and Validation

The platform's schema management system handles three types of violations: unplanned event types, unplanned event/user properties, and unplanned property values. Organizations can configure responses to either "Mark As Unexpected" or "Reject" each violation type. The Observe feature provides real-time monitoring by analyzing event streams against tracking plans, categorizing events with statuses (Unexpected, Valid, Invalid, Out of Date) and providing validation insights without requiring code changes.

Schema configuration supports complex data structures including property groups for bulk management, derived properties using formula editors with functions like REGEXEXTRACT, SPLIT, CONCAT, and mathematical operators, and lookup tables for enriching properties through CSV imports (limited to 100MB/1M rows with case-sensitive exact matching).

## Advanced Data Features

Amplitude Data includes sophisticated transformation capabilities that allow retroactive modification of event data structure at query time without affecting raw data in Snowflake/Redshift. These transformations support merging events/properties, renaming property values, and hiding values, applying only to the main branch while preserving raw data integrity.

The platform supports multi-currency revenue analysis through OOTB derived properties (Currency Converted Revenue/Price) and the CURRENCY_CONVERT() function, utilizing ISO 4217 currency codes and ExchangeRate API integration. Custom events functionality enables combining multiple existing events with OR clauses for tracking related user activities across various chart types.

## Integration Ecosystem

The platform maintains extensive integration capabilities through source and destination catalogs. Event streaming destinations enable real-time behavioral data forwarding to downstream marketing, sales, and infrastructure tools with 60-second p95 latency targets and exponential backoff retry mechanisms. Cohort synchronization supports three cadence options: one-time, scheduled (hourly/daily), and real-time (every minute) syncing with third-party destinations.

Specialized plugins extend functionality to popular platforms including Shopify (with Web Pixels API integration for checkout tracking) and WordPress (with advanced Autocapture functionality). The Chrome extension Amplitude Instrumentation Explorer provides real-time debugging capabilities for JS SDK instrumentation.

## Data Governance and Security

Enterprise-level data governance features include Data Access Control (DAC) for managing sensitive data through property classification (PII, revenue, sensitive) and group-based permissions. The system supports chart blocking, Event Stream restrictions, and export/subscription enforcement with customizable access controls.

Data mutability features enable INSERT, UPDATE, and DELETE operations through Mirror Sync strategies across Snowflake (CDC), Databricks (CDF), and Amazon S3 warehouse integrations. Time-to-Live (TTL) configuration allows organization and project-level event data retention with daily deletion jobs and configurable retention periods.

## Key API Endpoints and Technical Specifications

- **HTTP V2 API**: Real-time event ingestion with automatic location property enrichment
- **Batch Event Upload API**: Historical data import with rate limiting and deduplication
- **Taxonomy API**: CRUD operations for categories, event types, and properties
- **Evaluation API**: Experimentation feature support
- **User Privacy API**: GDPR/CCPA compliance for complete user deletion

The platform supports various data formats including CSV import/export for tracking plan schemas, converter configurations for Amazon S3 and Google Cloud Storage with comprehensive transformation operators, and Profiles integration using Change Data Capture for real-time user profile synchronization from data warehouses.