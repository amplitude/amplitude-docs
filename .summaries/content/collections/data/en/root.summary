Amplitude Data is a comprehensive data governance and management platform that provides tools for planning, implementing, and maintaining analytics instrumentation across the entire data lifecycle. The platform serves as a centralized data catalog that enables organizations to create structured tracking plans, generate type-safe code, monitor data quality, and transform data retroactively.

## Core Product Architecture

Amplitude Data operates as the governance layer above Amplitude Analytics, providing schema management and data quality controls. The platform integrates with multiple data ingestion methods including client-side SDKs (Browser, Android, iOS, React Native, Unity, Flutter), server-side SDKs (Node.js, Go, Python, Java), cloud storage imports (Amazon S3, Google Cloud Storage), warehouse integrations (Snowflake, Databricks), and third-party sources through the source catalog.

The platform follows a branch-based development model similar to Git, where users create feature branches from the main tracking plan, make changes, publish versions, undergo team reviews through merge requests, and merge back to main. This workflow ensures collaborative development and maintains data schema integrity across development and production environments.

## Key Features and Capabilities

**Tracking Plan Management**: The core feature enables creation of comprehensive tracking plans that define events, event properties, user properties, and group properties. These plans serve as the source of truth for analytics implementation and include metadata like descriptions, data types, validation rules, and categorization.

**Ampli Developer Tools**: Generates type-safe, autogenerated tracking libraries based on tracking plans using the `ampli pull` command. This provides compile-time validation, autocompletion, and prevents instrumentation errors by enforcing event names and property values at development time.

**Data Transformation**: Provides retroactive data modification capabilities including derived properties (computed using formulas with functions like REGEXEXTRACT, SPLIT, DATE_TIME_FORMATTER), transformations (merging events/properties, renaming values, hiding data), custom events (combining multiple events with OR clauses), and lookup tables (enriching properties via CSV imports up to 100MB/1M rows).

**Data Quality and Observability**: The Observe feature automatically monitors event streams against tracking plans, surfacing schema violations, missing properties, wrong data types, and out-of-date events. Visual Labeling enables no-code event creation through DOM element selection with Autocapture enabled (Browser SDK 2.10.0+ with `config.autocapture.elementInteractions`).

**Autocapture**: Automatically captures user interactions including Element Clicked, Element Changed, Page Viewed, Session Start/End, Form Started/Submitted, and File Downloaded events across Browser SDK, iOS Swift SDK, and Android-Kotlin SDK with minimal setup and configurable allowlists.

## Data Management and Access Control

**Schema Configuration**: Handles three types of schema violations - unplanned event types, unplanned properties, and unplanned property values - with options to mark as unexpected or reject data ingestion. Includes validation error monitoring and subscriber notifications.

**Data Access Control (DAC)**: Enterprise feature that classifies properties as PII, revenue, or sensitive data with group-based permissions enforcement across charts, cohorts, dashboards, exports, and the Taxonomy API.

**Data Filtering and Blocking**: Provides drop filters (query-time filtering), block filters (ingestion-time blocking including bot traffic using IAB/ABC International Spiders and Bots List), and permanent deletion capabilities for events and properties.

**Time-to-Live (TTL)**: Enterprise feature for configuring event data retention periods at organization and project levels with irreversible deletion warnings and 24-hour cancellation windows.

## Integration Ecosystem

**Destination Event Streaming**: Real-time behavioral data forwarding to downstream tools with p95 latency targets of 60 seconds, exponential backoff retry mechanisms, and configuration-based filtering. Supports streaming of transformed events including Custom Events, Derived Properties, and Transformed Properties.

**Cohort Synchronization**: Three sync cadence options - one-time, scheduled (hourly/daily), and real-time (every minute) - with third-party destinations including ad networks, attribution providers, and marketing automation platforms.

**Warehouse Integrations**: Data Mutability features enable INSERT, UPDATE, DELETE operations through Mirror Sync strategies using Change Data Capture (CDC) for Snowflake, Change Data Feed (CDF) for Databricks, and S3 integrations.

**Profiles Integration**: Joins customer profile data from warehouses with behavioral data using CDC with incremental modeling, supporting mutation_type operations and column mapping.

## Key Nomenclature and Definitions

**Events**: User actions or occurrences tracked in the system, following naming conventions like Title Case with Noun + Past Tense Verb syntax (e.g., "Product Viewed").

**Event Properties**: Attributes specific to individual events at the time they occurred, can be global (shared across events) or event-specific with override capabilities.

**User Properties**: Attributes of individual users that persist and update over time, including default properties (device type, location) and custom properties, with 14-month retention and operations like set, setOnce, unset, add, append, prepend.

**Group Properties**: Account-level properties for B2B analytics requiring the Accounts add-on, enabling organization-level reporting and analysis.

**Property Groups**: Collections of event properties that can be bulk-applied to multiple events with automatic propagation of updates across associated events.

**Sources**: SDK configurations within tracking plans that define the origin of events and enable source-specific validation and code generation.

**Channels**: Retroactive property classifiers based on UTM and referrer data for tracking acquisition channels with different plan limits and Data Tables integration.

## API Endpoints and Technical Implementation

**Taxonomy API**: Enables CRUD operations for categories, event types, event properties, and user properties, with restrictions that only planned events without existing project data can be edited.

**HTTP V2 API and Batch Event Upload**: Primary ingestion endpoints with limits of 500K events per device ID daily, 100 batches/1000 events per second, supporting `$skip_user_properties_sync` flag for backfill operations.

**Evaluation API**: Server-side endpoint for experiment tracking and feature flag evaluation.

**Ampli CLI Commands**: `ampli pull` for code generation, `ampli status --is-merged` for branch validation, integrated with Git workflows for tracking plan implementation.

The platform supports various data formats including CSV import/export for bulk tracking plan management, converter configurations for S3/GCS imports using `convertToAmplitudeFunc` with list operators, boolean operators, time conversion functions, and JSON manipulation operators.

## Specialized Tools and Extensions

**Chrome Extension (Event Explorer/Instrumentation Explorer)**: Real-time debugging tool for Amplitude JS SDK showing triggered events with event_type, user_id, device_id, event_properties, user_properties, and SDK configuration options.

**WordPress and Shopify Plugins**: Pre-built integrations with WordPress providing advanced Autocapture and Shopify offering standard e-commerce event tracking with Session Replay and Web Experiment capabilities.

**Cross-Project Analysis**: Portfolio feature combining up to 5 source projects with schema ranking for conflict resolution and Analytics-managed portfolio imports.

**Object Management**: Enterprise feature providing centralized management of reusable analysis objects including custom events, metrics, segments, and cohorts with bulk operations and duplicate detection.

The platform enforces role-based permissions (Admin/Manager/Member/Viewer) across all features and integrates with external tools like Jira for automatic issue creation during feature branch changes, supporting comprehensive data governance workflows for enterprise organizations.