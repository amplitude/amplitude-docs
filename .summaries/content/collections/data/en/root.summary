# Amplitude Data: Comprehensive Product Overview

## Product Overview

Amplitude Data is a comprehensive data governance and management platform designed to help organizations define, track, verify, and improve the quality of their analytics data. The platform provides tools for planning and instrumenting analytics tracking, managing data quality, and ensuring consistent implementation across products and teams. Key features include tracking plan management, data validation, transformation capabilities, and integration with development workflows.

Amplitude Data serves as the foundation for the broader Amplitude Analytics ecosystem, enabling organizations to collect high-quality behavioral data that can be analyzed to understand user behavior, optimize product experiences, and drive business outcomes.

## Product Relationships and Features

### Core Components

1. **Data Planning and Instrumentation**
   - **Tracking Plans**: Central repository for defining events, properties, and sources
   - **Ampli Developer Tools**: Type-safe SDK wrapper that generates code based on tracking plans
   - **Visual Labeling**: No-code event creation for websites with Autocapture enabled
   - **Autocapture**: Automatic collection of user interactions with minimal setup

2. **Data Management**
   - **Metadata Enrichment**: Add descriptions, display names, and categorizations to events and properties
   - **Data Transformations**: Retroactively modify event data without changing code
   - **Derived Properties**: Create new properties using formulas applied to existing data
   - **Data Cleanup**: Remove invalid data through drop filters, block filters, and deletion options

3. **Data Quality and Observability**
   - **Event Validation**: Compare incoming events against tracking plans
   - **AI Data Assistant**: Generate suggestions for tracking plan improvements
   - **Schema Configuration**: Control handling of unexpected data
   - **Instrumentation Explorer**: Chrome extension for debugging SDK implementation

4. **Integration and Connectivity**
   - **Source Integrations**: Connect to various data sources (SDKs, APIs, third-party platforms)
   - **Destination Event Streaming**: Share behavioral data with external tools
   - **Cohort Synchronization**: Export user segments to third-party platforms
   - **Profiles**: Join customer profile data from data warehouses with behavioral data

### Ecosystem Integration

Amplitude Data integrates with the broader Amplitude product ecosystem:

1. **Amplitude Analytics**: Data collected and managed through Amplitude Data powers analytics capabilities like funnels, user paths, and retention analysis.

2. **Amplitude Experiment**: Clean, well-structured data enables more effective experimentation and feature flagging.

3. **Amplitude CDP**: Data governance ensures high-quality data flows to customer data platform capabilities.

4. **Session Replay**: Integrates with data collection to provide visual context for user behavior.

5. **Third-Party Tools**: Data can be streamed to external platforms through destination integrations.

## Key Nomenclature and Definitions

### Data Structure Terminology

- **Events**: User actions or occurrences tracked in Amplitude (e.g., "Page Viewed", "Button Clicked")
- **Event Properties**: Attributes of specific events at the time they occur (e.g., page name, button text)
- **User Properties**: Attributes of individual users that persist across events (e.g., account type, country)
- **Group Properties**: Attributes of organizational units that users belong to (e.g., company plan type)
- **Property Groups**: Collections of properties that can be applied to multiple events simultaneously
- **Custom Events**: Combinations of multiple existing events with an OR clause
- **Derived Properties**: Properties created retroactively using formulas applied to existing properties

### Data Management Terminology

- **Tracking Plan**: Specification of events, properties, and sources that defines the expected data structure
- **Sources**: Origin points for data collection (client-side SDKs, server-side SDKs, third-party integrations)
- **Branches**: Isolated environments for making changes to tracking plans before merging to production
- **Schema Violations**: Unexpected data that doesn't match the defined tracking plan
- **Transformations**: Rules for modifying event data at query time without changing raw data
- **Drop/Block Filters**: Methods to filter out or prevent ingestion of unwanted data

### Implementation Terminology

- **Client-side Tracking**: Data collection from code running on user devices (mobile apps, web browsers)
- **Server-side Tracking**: Data collection from code running on servers
- **Autocapture**: Automatic collection of standard user interactions without manual instrumentation
- **Ampli**: Lightweight wrapper for Amplitude SDKs that provides type-safe event tracking

## Product Ecosystem Integration

Amplitude Data serves as the foundation for the entire Amplitude platform by ensuring high-quality data collection and management. The relationships between components include:

1. **Data Collection Flow**:
   - Client/server SDKs and integrations collect data according to tracking plans
   - Data passes through validation, transformation, and enrichment processes
   - Clean, structured data is stored and made available for analysis

2. **Development Workflow Integration**:
   - Tracking plans are created and managed in Amplitude Data
   - Developers use Ampli to implement tracking according to plans
   - Changes are reviewed and validated before deployment
   - Jira integration enables linking tracking plan changes to development tasks

3. **Cross-Project Analysis**:
   - Portfolios combine multiple source projects for unified analysis
   - Schema prioritization resolves conflicts between projects
   - Metadata overrides customize how combined data is presented

4. **Data Governance**:
   - Data Access Control restricts access to sensitive information
   - Time-to-Live settings manage data retention periods
   - Object management prevents duplication and establishes official definitions

## API Endpoints and Technical Implementation

### Amplitude Data API Endpoints

1. **Taxonomy API**: Programmatically manage Amplitude's data taxonomy
   - Endpoints for creating, retrieving, updating, and deleting:
     - Categories
     - Event types
     - Event properties
     - User properties

2. **Batch Event Upload API**: Used for data backfills and historical data imports
   - Endpoint: `https://api2.amplitude.com/batch`
   - Daily limit: 500,000 events
   - Batch limit: 100 batches per second

### SDK Implementation Options

1. **Client-side SDKs**:
   - Browser SDK (JavaScript/TypeScript)
   - iOS Swift SDK
   - Android-Kotlin SDK

2. **Server-side SDKs**:
   - Node.js
   - Python
   - Java
   - Go
   - Ruby
   - PHP

3. **SDK Configuration Options**:
   ```javascript
   // Example Browser SDK configuration
   amplitude.init('API_KEY', {
     // User identity
     userId: 'user@example.com',
     
     // Batching configuration
     batchEvents: true,
     eventUploadThreshold: 30,
     eventUploadPeriodMillis: 30000,
     
     // Tracking options
     trackingOptions: {
       ipAddress: false,
       city: true,
       region: true,
       dma: true,
       country: true
     },
     
     // Session configuration
     sessionTimeout: 30 * 60 * 1000
   });
   ```

4. **Ampli CLI Commands**:
   ```bash
   # Pull tracking plan from Amplitude Data
   ampli pull
   
   # Check status of local implementation
   ampli status
   
   # Generate type-safe SDK wrapper
   ampli generate
   ```

5. **Data Transformation Operators**:
   - String operators: `CONCAT`, `REPLACE`, `SUBSTRING`, `REGEXEXTRACT`
   - Math operators: `ADD`, `SUBTRACT`, `MULTIPLY`, `DIVIDE`
   - Boolean operators: `AND`, `OR`, `NOT`
   - Array operators: `CONTAINS`, `SPLIT`, `JOIN`
   - Conditional operators: `IF`, `SWITCH`, `CASE`

This comprehensive suite of tools and capabilities makes Amplitude Data a powerful platform for ensuring high-quality analytics data collection and management, enabling organizations to make data-driven decisions with confidence.