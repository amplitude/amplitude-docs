Amplitude Experiment is a feature flagging and experimentation platform that enables controlled rollouts and A/B testing through sophisticated assignment and exposure tracking mechanisms. The platform operates on a dual-event architecture where assignment events establish user variant membership while exposure events capture actual user interactions with experimental treatments, forming the foundation for statistical analysis and experiment integrity monitoring.

## Product Relationships and Features

The troubleshooting framework addresses four interconnected diagnostic domains within Amplitude Experiment:

**Event Tracking Architecture**: The platform's core functionality relies on the precise relationship between assignment events (generated during `fetch()` calls or remote evaluation) and exposure events (triggered through `variant()` calls). This dual-event system enables accurate measurement of user engagement with experimental variants while maintaining statistical validity through proper funnel analysis.

**Identity Resolution System**: User identity management operates across multiple identifier types including user ID, device ID, and Amplitude ID, handling complex scenarios such as anonymous user merging, account switching, and cross-device experiences. The identity consistency between assignment and exposure phases is critical for maintaining experiment integrity and preventing data contamination.

**Allocation and Distribution Engine**: Variant distribution is managed through configurable allocation weights, sticky bucketing mechanisms for consistent user experiences, and bucketing salts for controlled randomization. These components ensure proper statistical distribution while maintaining user assignment stability across sessions and interactions.

**Diagnostic and Monitoring Infrastructure**: Built-in diagnostic capabilities include the "Exposures without Assignments" chart for identifying tracking gaps, sample ratio mismatch (SRM) detection for allocation validation, and comprehensive user timeline analysis for troubleshooting individual user journeys through experiments.

## Key Nomenclature and Definitions

**Assignment Event**: System-generated event occurring when users are bucketed into variants through SDK `fetch()` calls or remote evaluation, establishing definitive experimental group membership for statistical analysis.

**Exposure Event**: User-triggered event generated when participants actually encounter variant experiences through `variant()` calls, representing genuine interaction with experimental treatments and forming the basis for conversion analysis.

**Variant Jumping**: Condition where users are exposed to multiple variants within a single experiment, occurring through legitimate operational changes (allocation adjustments, targeting modifications) or problematic scenarios (identity conflicts, configuration errors).

**Sample Ratio Mismatch (SRM)**: Statistical anomaly where observed variant allocation significantly deviates from configured allocation percentages, indicating potential experiment integrity issues requiring investigation and remediation.

**Sticky Bucketing**: Persistence mechanism ensuring users maintain consistent variant assignments across sessions and interactions, preventing user experience fragmentation and maintaining statistical validity.

**Bucketing Key/Salt**: Randomization parameters controlling user assignment distribution across variants, with salt modifications enabling controlled experiment rerandomization while maintaining assignment consistency.

**Fallback Variant**: Default variant served when users fail to meet targeting criteria or during system failures, requiring careful exposure tracking to prevent analysis contamination and maintain statistical accuracy.

**Experiment Key**: Unique identifier property enabling differentiation between experiment runs and historical data exclusion, facilitating clean analysis boundaries when creating new experiment iterations.

## Broader Product Ecosystem Integration

Amplitude Experiment integrates comprehensively with the Amplitude analytics ecosystem through shared event architecture and unified identity resolution systems. The platform leverages Amplitude's behavioral tracking infrastructure to maintain consistent user identification and experience delivery across multiple touchpoints and interaction channels.

The experimentation framework supports both remote evaluation (server-side assignment with centralized decision-making) and local evaluation (client-side assignment with distributed processing) patterns. SDKs handle automated exposure tracking and variant delivery while integrating with Amplitude's analytics engine for sophisticated funnel analysis spanning assignment, exposure, and conversion events.

Mutual exclusion capabilities enable experiment coordination and resource allocation management, preventing users from participating in conflicting experiments simultaneously. This ecosystem approach ensures experimental validity while maintaining optimal user experience quality and preventing statistical interference between concurrent tests.

## API Endpoints and Technical Implementation

**Core SDK Methods**:
- `fetch()`: Retrieves variant assignments from evaluation engine and automatically generates assignment events for statistical tracking
- `variant()`: Accesses variant configuration values and triggers exposure events for user interaction measurement

**Evaluation API**: Supports `experiment_key` parameter for experiment run differentiation, enabling historical data exclusion and clean analysis boundaries across experiment iterations.

**Event Properties and Parameters**:
- `expKey`: Variant-level property containing experiment key for run-specific analysis and data segmentation
- Bucketing parameters controlling assignment randomization and distribution logic
- Identity resolution properties for cross-device and cross-session user tracking

**Diagnostic and Analysis Endpoints**: User timeline analysis capabilities and assignment-to-exposure funnel tracking through Amplitude's event stream infrastructure, enabling comprehensive troubleshooting and experiment health monitoring.

The platform requires specific SDK versions to support advanced features including experiment keys and enhanced diagnostic capabilities, with version compatibility determining available troubleshooting tools and analysis functionality for experiment optimization and issue resolution.