## Summary
This documentation covers Amplitude's Databricks import source integration that uses Databricks Change Data Feed (CDF) to import events, user properties, and group properties with delta sync support, including configuration of all-purpose compute clusters, personal access tokens, SQL transformations, and troubleshooting for JDBC connection issues.

## Keywords
- Databricks Change Data Feed (CDF)
- delta sync operations
- all-purpose compute cluster
- personal access tokens (PAT)
- service principal authentication
- Mirror Sync vs Append Only Sync
- JDBC connection configuration
- server hostname HTTP path
- SQL transformations
- unity catalog permissions
- Data Reader permissions
- cluster access modes
- CDF table versioning
- batch event upload API
- workspace user authentication
- time travel limitations
- User Privacy API integration
- event volume impact
- PERMISSION_DENIED errors
- communication link failure troubleshooting