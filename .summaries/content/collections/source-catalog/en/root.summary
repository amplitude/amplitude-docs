Amplitude's Source Catalog represents a comprehensive ecosystem of data integrations that enables organizations to centralize behavioral analytics by ingesting data from diverse platforms and tools. The catalog encompasses over 60 integrations spanning marketing automation, attribution tracking, customer engagement, subscription management, data warehouses, and experimentation platforms.

## Core Integration Architecture

The source catalog operates on multiple integration types that define how data flows into Amplitude:

**Raw-Events Integration** serves as the primary ingestion method, streaming event data directly into Amplitude's analytics platform. This type supports real-time behavioral tracking from platforms like Braze, Intercom, HubSpot, and mobile attribution providers.

**Event-Streaming Integration** enables bidirectional data flow, allowing both data ingestion and export capabilities. Sources like Segment, AppsFlyer, and Branch utilize this pattern for comprehensive cross-platform analytics.

**Cohorts Integration** facilitates audience segmentation by both importing user segments and exporting Amplitude behavioral cohorts to external platforms for targeted campaigns and personalization.

**Attribution Integration** leverages Amplitude's Attribution API to process mobile attribution data from providers like Adjust, AppsFlyer, and Singular, supporting advertising ID matching (IDFA/IDFV/ADID) with 72-hour attribution windows.

## Data Warehouse and ETL Ecosystem

The catalog includes sophisticated warehouse integrations supporting multiple sync strategies:

**Snowflake Integration** provides the most comprehensive warehouse connectivity with Change Data Capture (CDC), Mirror Sync operations (insert/update/delete), Append Only Sync, Timestamp-based imports, and Full Sync strategies. It supports key pair authentication, S3 Storage Integration, and handles VARIANT JSON data types with OBJECT_CONSTRUCT functions.

**BigQuery Integration** enables GA4 data imports through BigQuery linking, requiring GCS bucket configuration and Service Account permissions (BigQuery Job User, BigQuery Data Viewer, Storage Admin). It handles STRUCT type columns and supports JSON_EXTRACT_SCALAR transformations for complex data structures.

**Databricks Integration** utilizes Change Data Feed (CDF) for delta sync operations with all-purpose compute clusters, personal access tokens, and Unity Catalog permissions.

**Amazon S3 and Google Cloud Storage** provide file-based ingestion with converter configuration, supporting JSON/CSV/parquet formats, IAM role setup, and both Mirror Sync and Append Only import strategies.

## Marketing and Attribution Ecosystem

The catalog extensively covers marketing attribution and campaign analytics:

**Mobile Attribution Providers** (AppsFlyer, Adjust, Branch, Kochava, Singular) integrate via the Attribution API, enabling real-time attribution tracking with advertising ID matching and supporting Self-Reporting Networks (SRN) with specific privacy considerations.

**Advertising Platforms** (Facebook Ads, Google Ads) import campaign-level metrics as "Daily Ad Metrics" events, including properties like ad_metrics.impressions, ad_metrics.clicks, ad_group_id, and UTM parameter mapping for CAC/ROAS calculations.

**Email and Marketing Automation** (HubSpot, Mailchimp, SendGrid, Braze) stream engagement events (opens, clicks, deliveries) with specific event prefixes like "[HubSpot]" or "[Sendgrid]" for easy identification.

## Customer Engagement and Experience Platforms

**Subscription and Revenue Tracking** integrations (RevenueCat, Adapty, Apphud, Nami, Stripe) focus on mobile app monetization, streaming subscription events, in-app purchase data, and revenue analytics with user ID matching requirements.

**Customer Support and Messaging** (Intercom, OneSignal, Cordial) provide conversational analytics with event categorization by topics (conversation, contact, user, visitor) and support for push notifications, email, SMS, and in-app messaging events.

**Survey and Feedback Platforms** (Qualtrics, Sprig, Survicate, Blitzllama) enable qualitative feedback analysis with automatic email-based User_ID mapping and survey response event streaming.

## Product Experience and Onboarding

**User Onboarding Platforms** (Userflow, Userguiding, Bento, Chameleon) track product tour completion, step progression, and guide engagement with events like "Flow Started" and "Checklist Task Completed" for analyzing onboarding funnel performance.

**Experimentation and Feature Management** (Optimizely, Split, Taplytics) integrate A/B testing data with experiment variation tracking, feature flag impression data, and treatment analysis for Impact-Driven Development workflows.

## Key Technical Specifications

**Authentication Methods** vary by integration type: OAuth flows (Intercom, HubSpot, Mailchimp), API key authentication (most sources), Service Account configurations (warehouse sources), and webhook-based authentication (SendGrid, Stripe).

**User Identity Mapping** requires careful configuration across platforms, supporting various identifier types: user_id, device_id, email addresses, Advertising IDs (IDFA/IDFV/ADID), and custom identifier fields like amplitudeDeviceId or customerUserId.

**Data Delivery Patterns** range from real-time streaming to batch processing with specific intervals: 30-minute delivery (Convizit), hourly syncing (HubSpot), daily imports (advertising platforms), and real-time webhooks (most engagement platforms).

**Regional Considerations** include EU data residency support for GDPR compliance, with specific endpoint configurations (api.eu.amplitude.com) and data center selection options for various integrations.

The source catalog represents Amplitude's strategy to become the central hub for behavioral analytics by providing native integrations across the entire customer data ecosystem, enabling organizations to unify disparate data sources into comprehensive user journey analytics and behavioral insights.