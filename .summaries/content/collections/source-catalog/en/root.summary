## Amplitude Source Catalog

The Amplitude Source Catalog provides data warehouse integrations that enable organizations to import events, user properties, group properties, and user profiles from enterprise data platforms into Amplitude analytics projects. The catalog currently supports major cloud data warehouses including Databricks and Snowflake, offering flexible synchronization strategies and authentication methods to accommodate various enterprise data architectures.

## Product Relationships and Integration Architecture

The source catalog integrations operate as bidirectional data connectors between enterprise data warehouses and Amplitude's analytics platform. Both Databricks and Snowflake integrations share common architectural patterns:

**Data Import Capabilities**: All integrations support importing events, user properties, group properties, and user profiles into Amplitude projects, enabling comprehensive user behavior analysis across the entire customer journey.

**Synchronization Strategies**: The integrations offer multiple sync approaches including Full Sync for complete data refreshes, Timestamp-based syncing for incremental updates, Append Only Sync for write-only scenarios, and Mirror Sync for maintaining exact replicas with Change Data Capture (CDC) capabilities.

**Authentication Framework**: Both platforms support enterprise-grade authentication including personal access tokens (PAT), service principal authentication for Databricks, and key pair authentication for Snowflake, ensuring secure data access within organizational security policies.

## Key Nomenclature and Definitions

**Change Data Feed (CDF)**: Databricks-specific feature that tracks data changes at the table level, enabling efficient delta synchronization by capturing only modified records rather than full table scans.

**Change Data Capture (CDC)**: Snowflake's methodology for identifying and capturing data modifications, supporting real-time data synchronization between the warehouse and Amplitude.

**Mirror Sync vs Append Only Sync**: Mirror Sync maintains an exact replica of source data with support for updates and deletions, while Append Only Sync exclusively adds new records without modifying existing data.

**Delta Sync**: Incremental synchronization approach that transfers only changed data since the last sync operation, optimizing performance and reducing data transfer overhead.

**Unity Catalog**: Databricks' unified governance solution requiring specific Data Reader permissions for accessing tables and managing cluster access modes.

**Insert ID**: Unique identifier used for event deduplication, preventing duplicate event ingestion during synchronization processes.

## Broader Product Ecosystem Integration

The source catalog integrations function as critical data ingestion components within Amplitude's broader analytics ecosystem. They connect upstream enterprise data warehouses to downstream analytics capabilities including:

**User Privacy API Integration**: Both integrations respect user privacy controls and deletion requests processed through Amplitude's User Privacy API, ensuring compliance with data protection regulations.

**Enrichment Services**: Integrations can disable Amplitude's automatic enrichment services when raw data fidelity is required, providing control over data processing pipelines.

**Regional Data Compliance**: Support for regional IP allowlists ensures data remains within specified geographic boundaries, supporting global organizations with data residency requirements.

## Technical Implementation Details

**Databricks Integration**:
- Requires all-purpose compute clusters (not serverless or job clusters)
- Uses JDBC connections for data access
- Supports SQL-based data transformation during import
- Implements table versioning for change tracking
- Configurable sync frequency based on event volume requirements

**Snowflake Integration**:
- Utilizes VARIANT JSON data type for flexible schema handling
- Implements OBJECT_CONSTRUCT function for complex data mapping
- Supports TIMESTAMP_NTZ format for timezone-neutral timestamps
- Requires ABORT_DETACHED_QUERY setting for connection management
- Enforces DATA_RETENTION_TIME_IN_DAYS for historical data access
- Implements 12-hour query timeout with 1B events batch limit
- Supports storage integration with external stages for large data transfers

**Common Technical Features**:
- EPOCH_MILLISECOND timestamp extraction for precise event timing
- SQL query mapping for custom data transformation
- Regional IP allowlist configuration for network security
- Configurable sync strategies based on data update patterns
- Event volume impact considerations for performance optimization

The source catalog represents Amplitude's commitment to enterprise data integration, providing robust, scalable solutions for organizations requiring sophisticated data warehouse connectivity while maintaining security, compliance, and performance standards.