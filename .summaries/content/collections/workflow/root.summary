# Amplitude Experiment

Amplitude Experiment is a comprehensive experimentation and feature flag platform that enables teams to run A/B tests, multi-armed bandit experiments, and manage feature rollouts. The platform supports both traditional hypothesis-driven testing and automated optimization through machine learning algorithms, providing statistical analysis tools and real-time traffic allocation capabilities.

## Product Architecture and Feature Relationships

The platform operates through a hierarchical structure where **experiments** and **feature flags** are deployed through **deployments** (client-side or server-side) that generate unique access keys for SDK integration. Each experiment contains multiple **variants** with configurable traffic distribution, targeting specific **user segments** defined by cohorts, user properties, or custom attributes.

The experimentation workflow follows a structured pipeline: experiment creation → audience definition → goal configuration → variant setup → delivery configuration → statistical preferences → testing/launch → analysis. Feature flags follow a simplified path focused on rollout management rather than statistical testing.

**Multi-armed bandit experiments** represent an advanced capability that uses Thompson sampling to automatically reallocate traffic toward better-performing variants based on a primary optimization metric, contrasting with traditional A/B tests that maintain fixed traffic allocation until statistical significance is reached.

## Key Nomenclature and Definitions

**Bucketing Unit**: The entity used for experiment assignment (User ID, Device ID, Company ID, etc.), following the Stable Unit Treatment Value Assumption (SUTVA)

**Variants**: Different versions of an experiment including control/baseline and treatment variants, each with names, values (slugified for SDK consumption), payloads (JSON), and traffic allocation percentages

**Exposure Event**: Triggered when `.variant()` method is called, indicating actual user interaction with the experiment, distinct from assignment events

**Evaluation Modes**: 
- **Remote Evaluation**: Server-side variant determination with real-time targeting
- **Local Evaluation**: Client-side evaluation using cached rules and configurations

**User Segments**: Rule-based targeting criteria using cohorts (hourly sync), user properties (real-time), or custom properties for experiment eligibility

**Rollout Percentage**: Controls what portion of eligible users enter the experiment bucketing process

**Statistical Methods**:
- **CUPED**: Variance reduction technique using pre-exposure data
- **Sequential Testing**: Continuous monitoring vs traditional T-test approaches
- **Bonferroni Correction**: Multiple hypothesis testing adjustment

## Product Ecosystem Integration

Amplitude Experiment integrates deeply with the broader Amplitude analytics ecosystem, leveraging user cohorts, behavioral data, and event tracking for targeting and analysis. The platform connects through:

- **Amplitude SDKs**: Multi-language client libraries for variant retrieval and exposure tracking
- **REST API**: Programmatic flag evaluation and configuration management
- **Analytics Integration**: Automatic exposure event generation and conversion tracking
- **Notification Systems**: Slack webhooks for experiment status and statistical significance alerts

The platform supports enterprise features including mutual exclusion groups, holdout testing, and advanced statistical preferences, positioning it as both a standalone experimentation tool and an integrated component of Amplitude's product analytics suite.

## API Endpoints and Technical Integration

Key technical touchpoints include:
- **`.variant()` method**: Primary SDK method for variant retrieval and exposure event triggering
- **Evaluation REST API**: Server-side flag evaluation for non-SDK implementations
- **Deployment Access Keys**: Authentication tokens generated per deployment for SDK configuration
- **User Context Objects**: Required data structures containing user identifiers and properties for targeting
- **Test Instrumentation**: QA testing framework using designated tester assignments with user/device/cohort IDs

The platform emphasizes both ease of use for product teams and technical flexibility for engineering teams, supporting offline mode variants, multi-user deployments, and comprehensive diagnostic tools including Root Cause Analysis for variant assignment monitoring and Sample Ratio Mismatch (SRM) detection.