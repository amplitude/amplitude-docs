# Amplitude Experiment Product Overview

Amplitude Experiment is a comprehensive experimentation and feature flagging platform that enables product teams to test hypotheses, roll out features safely, and make data-driven decisions. The platform supports both A/B testing and Multi-Armed Bandit experiments, with capabilities for both client-side and server-side implementations.

## Key Features and Concepts

### Experiment Types
- **A/B Testing**: Traditional hypothesis testing with static traffic allocation
- **Multi-Armed Bandit**: Automated traffic reallocation to better-performing variants using Thompson sampling
- **Feature Flag Rollouts**: Controlled feature releases without formal experimentation

### Evaluation Modes
- **Remote Evaluation**: Server-side evaluation where Amplitude's servers determine variant assignment
- **Local Evaluation**: Client-side evaluation where the SDK determines variant assignment locally

### Core Components
- **Deployments**: Configuration entities that connect to Analytics projects and contain deployment keys for SDK integration
- **Variants**: Different versions of an experience being tested (including control variant)
- **Bucketing Units**: Entities used for randomization (user ID, device ID, etc.)
- **Audiences**: Targeting criteria that determine which users are eligible for experiments
- **Goals/Metrics**: Success measurements for experiments (recommendation metrics, secondary metrics, guardrail metrics)

## Product Relationships and Architecture

### Integration with Amplitude Analytics
Amplitude Experiment is tightly integrated with Amplitude Analytics, allowing for:
- Sharing user contexts between platforms
- Using Analytics cohorts for experiment targeting
- Analyzing experiment results using Analytics data
- Tracking exposure events that determine when users enter experiments

### Deployment Types
1. **Client-side Deployments**: 
   - Used for web and mobile applications
   - Typically implemented with JavaScript, iOS, or Android SDKs
   - Better for UI/UX experiments

2. **Server-side Deployments**:
   - Used for backend services and APIs
   - Implemented with server-side SDKs (Node.js, Java, etc.)
   - Better for algorithm or business logic experiments

### Experiment Workflow
The platform supports a complete experimentation workflow:
1. Creation and configuration
2. Audience definition
3. Variant setup
4. Goal definition
5. Statistical preference configuration
6. Testing and QA
7. Launch and monitoring
8. Results analysis
9. Implementation of learnings

## Key Nomenclature and Definitions

- **Variant**: A specific version of a feature or experience being tested
- **Control Variant**: The baseline version against which other variants are compared
- **Variant Payload**: JSON data structure containing configuration for a variant
- **Bucketing**: The process of assigning users to experiment variants
- **Bucketing Salt**: A value that ensures consistent but random variant assignment
- **Exposure Event**: The event that triggers a user to be included in an experiment
- **Minimum Detectable Effect (MDE)**: The smallest meaningful difference an experiment can detect
- **Statistical Significance**: The confidence level that observed differences are not due to chance
- **CUPED (Controlled-experiment Using Pre-Existing Data)**: A variance reduction technique
- **Bonferroni Correction**: A method to adjust for multiple hypothesis testing
- **Sequential Testing**: Statistical approach that allows for continuous monitoring of results
- **Variant Jumping**: When a user receives different variants across sessions (usually undesirable)
- **Sample Ratio Mismatch**: When the actual distribution of users differs from the intended distribution

## Product Ecosystem Integration

Amplitude Experiment functions as part of the broader Amplitude product suite:

1. **Amplitude Analytics**: Provides user behavior data for targeting and analysis
2. **Amplitude Cohorts**: Used for audience targeting in experiments
3. **Amplitude SDKs**: Enable implementation across platforms (web, mobile, server)
4. **Amplitude Data**: Powers the statistical analysis and results visualization

The platform is designed to work with various development workflows through:
- SDK implementations for multiple languages and platforms
- API endpoints for programmatic control
- CDN-based delivery for client-side implementations

## Technical Implementation

### SDK Integration
Amplitude Experiment requires installing the appropriate SDK for your platform:
- Client-side: JavaScript, iOS, Android
- Server-side: Node.js, Java, Python, Go, Ruby

### Key API Concepts
- **User Context**: Contains user identifiers (user ID, device ID) and properties used for targeting
- **Variant Assignment**: The process of determining which variant a user receives
- `variant()` function: Used to retrieve the assigned variant for a user

### Implementation Flow
1. Initialize the SDK with deployment key
2. Create user context with appropriate identifiers
3. Fetch variants for experiments
4. Implement conditional logic based on variant assignment
5. Track exposure events when users encounter the experiment

## Statistical Analysis Features

- **Duration Estimator**: Calculates required sample size and experiment runtime
- **Multiple Testing Methods**: T-test and Sequential testing
- **Confidence Levels**: Configurable (default 95%)
- **Variance Reduction**: Optional CUPED implementation
- **Multiple Comparison Correction**: Bonferroni correction for multiple metrics

## Troubleshooting and Diagnostics

The platform provides several diagnostic tools:
- Data Quality checks for experiment integrity
- Diagnostics card for identifying implementation issues
- Sample ratio mismatch detection
- Variant jumping identification
- QA tools for pre-launch verification